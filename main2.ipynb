{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H-yiaJcnfRE_",
        "outputId": "3c0e7dd1-b5f6-47e3-c802-55c13b0b6619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 13 11:12:09 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0              29W /  70W |    709MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QI_0pStjkQP3",
        "outputId": "8e61cc51-2255-4755-fe1b-73fde1cfcbb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒŸ Dependencies Used:\n",
        "\n",
        "1. **noisereduce**: library in Python is utilized for noise reduction in audio files.\n",
        "2. **openai-whisper**: OpenAI's Whisper is a powerful open-source speech recognition system that can transcribe speech in multiple languages and translate non-English speech to English.\n",
        "3. **whisperx**: library is a Python package that provides fast and accurate automatic speech recognition (ASR) with word-level timestamps and speaker diarization. It is built on top of OpenAI's Whisper model and uses CTranslate2 for faster inference.\n",
        "4. **pydub**: pydub is a high-level audio manipulation library that provides a simple and easy-to-use interface.\n",
        "5. **pysrt**: pysrt is a library used for parsing and editing SubRip (.srt) subtitle files.\n"
      ],
      "metadata": {
        "id": "T07M5JoqvEEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce openai-whisper git+https://github.com/m-bain/whisperx.git git+https://github.com/openai/whisper.git pydub pysrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rraa9ZlJfFEc",
        "outputId": "c330f4a4-09ce-48d3-e26a-e85c89008a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/m-bain/whisperx.git\n",
            "  Cloning https://github.com/m-bain/whisperx.git to /tmp/pip-req-build-5o2ywfc0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperx.git /tmp/pip-req-build-5o2ywfc0\n",
            "  Resolved https://github.com/m-bain/whisperx.git to commit f2da2f858e99e4211fe4f64b5f2938b007827e17\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-yqcb3_k_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-yqcb3_k_\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: pysrt in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.7.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from noisereduce) (0.10.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.4)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n",
            "Requirement already satisfied: torchaudio>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.2.1+cu121)\n",
            "Requirement already satisfied: faster-whisper==1.0.0 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (1.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (4.39.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.0.3)\n",
            "Requirement already satisfied: setuptools>=65 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (67.7.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.8.1)\n",
            "Requirement already satisfied: pyannote.audio==3.1.1 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.1.1)\n",
            "Requirement already satisfied: av==11.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (11.0.0)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (4.2.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.15.2)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (1.17.3)\n",
            "Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.0)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.8.0)\n",
            "Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.4)\n",
            "Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.3.0)\n",
            "Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.0.0)\n",
            "Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.0)\n",
            "Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.2.1)\n",
            "Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n",
            "Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.5.0)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (13.7.1)\n",
            "Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n",
            "Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.0)\n",
            "Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.6.2.2)\n",
            "Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.1)\n",
            "Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from pysrt) (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.127)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->noisereduce) (1.0.8)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (2023.12.25)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2024.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (0.4.3)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.2)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.9.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (3.20.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->noisereduce) (4.2.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\n",
            "Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.3)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.9.0)\n",
            "Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->noisereduce) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.16.0)\n",
            "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.99)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.7)\n",
            "Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.4)\n",
            "Requirement already satisfied: pretty-errors==1.2.25 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.25)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from pretty-errors==1.2.25->torchmetrics>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.22)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch->openai-whisper==20231117) (3.9.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.2)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.30)\n",
            "Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.5.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (10.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.18.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch->openai-whisper==20231117) (4.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.3)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸŒŸ\n",
        "1. librosa: to load the audio MP3 files and extract features if needed.\n",
        "2. soundfile to save the denoised audio after noise reduction.\n",
        "3. noisereduce to apply noise reduction techniques to clean up the audio.\n",
        "4. Whisper library for speech-to-text transcription of the denoised audio.\n",
        "5. pysrt to parse, edit, and save the subtitles in SubRip (.srt) format.\n",
        "6. pydub for additional audio manipulation tasks."
      ],
      "metadata": {
        "id": "_i4z7gW1xmf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "import noisereduce as nr\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "import pysrt\n",
        "import os"
      ],
      "metadata": {
        "id": "gP8GFW1lkQSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŸ loading the yt video mp3 file (.mp3) converted from mp4->mp3"
      ],
      "metadata": {
        "id": "n_x2DGHHyCgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mp3_path = '/content/drive/My Drive/aud.mp3'"
      ],
      "metadata": {
        "id": "i5G5thUBrIt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the noisy audio file\n",
        "noisy_audio, sr = librosa.load(mp3_path, sr=None)"
      ],
      "metadata": {
        "id": "a4WsLxpzrIy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply noise reduction\n",
        "denoised_audio = nr.reduce_noise(y=noisy_audio, sr=sr)"
      ],
      "metadata": {
        "id": "EbB52W0BrI5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save denoised audio\n",
        "sf.write('/content/drive/My Drive/denoised_audio2.mp3', denoised_audio, sr)"
      ],
      "metadata": {
        "id": "AalfOMk4qd8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŸ Reasons to Use Whisper Base Model for Speech-to-Text\n",
        "1. Robust Performance: The Whisper base model is trained on a large and diverse dataset of 680,000 hours of audio, making it robust to accents, background noise, and technical language.\n",
        "2. Multilingual Support: Whisper supports transcription in 99 different languages, allowing you to handle a wide range of speech inputs.\n",
        "3. Open-Source and Free: Unlike other speech recognition models, Whisper is open-source and freely available, reducing the cost and barriers to entry.\n",
        "\n",
        "### ðŸŒŸ Advantages of Whisper Base Model\n",
        "1. Strong Generalization:.\n",
        "2. Multitasking Capabilities."
      ],
      "metadata": {
        "id": "vK13bDzsyjdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ðŸŒŸ The transcribe() function will load the audio file, preprocess it, and pass it through the loaded Whisper model to generate a transcription."
      ],
      "metadata": {
        "id": "lP7YgS31y5fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"/content/drive/My Drive/denoised_audio2.mp3\")"
      ],
      "metadata": {
        "id": "PDPwYbTKpEkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/My Drive/aud_transcription.txt\", \"w\") as f:\n",
        "    f.write(result[\"text\"])"
      ],
      "metadata": {
        "id": "OFX0g6NGpEm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŸ Command Explanation ( for Time-aligning)\n",
        "\n",
        "This command utilizes the `whisperx` tool to process audio files in a semantic chunking project, specifically for converting YouTube videos into properly aligned transcriptions.\n",
        "\n",
        "```bash\n",
        "!whisperx /content/drive/MyDrive/denoised_audio.mp3 --model medium.en --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H\n",
        "```\n",
        "\n",
        "- **`!whisperx`**: Executes the `whisperx` tool for audio processing.\n",
        "- **`/content/drive/MyDrive/denoised_audio.mp3`**: Path to the input audio file, located in Google Drive.\n",
        "- **`--model medium.en`**: Specifies the model to be used for processing, a medium-sized English language model.\n",
        "- **`--output_dir .`**: Sets the output directory to the current directory for saving processed files.\n",
        "- **`--align_model WAV2VEC2_ASR_LARGE_LV60K_960H`**: Specifies the alignment model to be used, leveraging techniques from the WAV2VEC2 architecture.\n"
      ],
      "metadata": {
        "id": "7sGi83Z7zjqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisperx /content/drive/MyDrive/denoised_audio.mp3 --model medium.en --output_dir . --align_model WAV2VEC2_ASR_LARGE_LV60K_960H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xCckh5rSO_0R",
        "outputId": "805030bf-73c7-4265-f20e-445bdd933d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-13 11:19:14.418725: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-13 11:19:14.418779: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-13 11:19:14.420180: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-13 11:19:15.536553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
            "  torchaudio.set_audio_backend(\"soundfile\")\n",
            "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.2.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/whisperx-vad-segmentation.bin`\n",
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.2.1+cu121. Bad things might happen unless you revert torch to 1.x.\n",
            ">>Performing transcription...\n",
            ">>Performing alignment...\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒŸ Semantic Chunking Function\n",
        "\n",
        "## Overview\n",
        "\n",
        "The `semantic_chunking` function processes audio and subtitle files to perform semantic chunking, dividing the audio into smaller segments aligned with corresponding subtitles..\n",
        "\n",
        "## Function Signature\n",
        "\n",
        "```python\n",
        "def semantic_chunking(audio_file, srt_file)\n",
        "```\n",
        "\n",
        "## Parameters:\n",
        "\n",
        "audio_file (str): Path to the input audio file.\n",
        "srt_file (str): Path to the input subtitle file in SRT format.\n",
        "\n",
        "## ðŸŒŸ Returns:\n",
        "\n",
        "1. chunks (list of dicts): A list containing dictionaries representing each chunk with the following keys:\n",
        "2. chunk_id (int): Unique identifier for the chunk.\n",
        "3. chunk_length (float): Length of the chunk in seconds.\n",
        "4. text (str): Textual content corresponding to the chunk.\n",
        "5. start_time (float): Start time of the chunk in seconds.\n",
        "6. end_time (float): End time of the chunk in seconds."
      ],
      "metadata": {
        "id": "AvpoIx8c0loS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform semantic chunking and generate output in the specified format\n",
        "def semantic_chunking(audio_file, srt_file):\n",
        "    # Load audio\n",
        "    audio = AudioSegment.from_file(audio_file)\n",
        "\n",
        "    # Load subtitles\n",
        "    subs = pysrt.open(srt_file)\n",
        "\n",
        "    # Chunk duration in milliseconds (15 seconds)\n",
        "    chunk_duration = 15 * 1000\n",
        "\n",
        "    # Initialize start and end times\n",
        "    start_time = 0\n",
        "    end_time = chunk_duration\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    # Unique identifier for chunks\n",
        "    chunk_id = 1\n",
        "\n",
        "    # Segment audio and text\n",
        "    for sub in subs:\n",
        "        # Calculate end time of current subtitle\n",
        "        sub_end_time = sub.end.to_time().hour * 3600 * 1000 + \\\n",
        "                       sub.end.to_time().minute * 60 * 1000 + \\\n",
        "                       sub.end.to_time().second * 1000 + \\\n",
        "                       sub.end.to_time().microsecond / 1000\n",
        "\n",
        "        # Segment audio and text until end of subtitle\n",
        "        while start_time < sub_end_time:\n",
        "            # Ensure end time doesn't exceed end of subtitle\n",
        "            if end_time > sub_end_time:\n",
        "                end_time = sub_end_time\n",
        "\n",
        "            # Extract audio chunk\n",
        "            chunk_audio = audio[start_time:end_time]\n",
        "\n",
        "            # Extract text chunk\n",
        "            chunk_text = ''\n",
        "            for line in sub.text.split('\\n'):\n",
        "                chunk_text += line + ' '\n",
        "\n",
        "            # Calculate chunk length in seconds\n",
        "            chunk_length = len(chunk_audio) / 1000\n",
        "\n",
        "            # Append chunk to list\n",
        "            chunks.append({\n",
        "                \"chunk_id\": chunk_id,\n",
        "                \"chunk_length\": chunk_length,\n",
        "                \"text\": chunk_text.strip(),\n",
        "                \"start_time\": start_time / 1000,\n",
        "                \"end_time\": end_time / 1000\n",
        "            })\n",
        "\n",
        "            # Move to next chunk\n",
        "            start_time = end_time\n",
        "            end_time += chunk_duration\n",
        "\n",
        "            # Increment chunk id\n",
        "            chunk_id += 1\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "aVDIL0vOO_mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Paths to audio and srt files\n",
        "    audio_file = \"/content/drive/MyDrive/denoised_audio.mp3\"\n",
        "    srt_file = \"/content/denoised_audio.srt\"\n",
        "\n",
        "    # Perform semantic chunking\n",
        "    chunks = semantic_chunking(audio_file, srt_file)\n",
        "\n",
        "    # Output chunks\n",
        "    print(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulDYXarQUu2-",
        "outputId": "c49bc9aa-f066-45ca-9229-af275bd33757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'chunk_id': 1, 'chunk_length': 2.09, 'text': 'Congratulations to you Mr. Raghavan for that.', 'start_time': 0.0, 'end_time': 2.09}, {'chunk_id': 2, 'chunk_length': 1.34, 'text': 'Thank you so much for joining us.', 'start_time': 2.09, 'end_time': 3.43}, {'chunk_id': 3, 'chunk_length': 0.801, 'text': 'Over to you.', 'start_time': 3.43, 'end_time': 4.231}, {'chunk_id': 4, 'chunk_length': 5.101, 'text': 'Hi everybody.', 'start_time': 4.231, 'end_time': 9.332}, {'chunk_id': 5, 'chunk_length': 0.721, 'text': 'How are you?', 'start_time': 9.332, 'end_time': 10.053}, {'chunk_id': 6, 'chunk_length': 3.501, 'text': 'I am not hearing this at all.', 'start_time': 10.053, 'end_time': 13.554}, {'chunk_id': 7, 'chunk_length': 3.381, 'text': \"It's like a post-lunch energy downer or something.\", 'start_time': 13.554, 'end_time': 16.935}, {'chunk_id': 8, 'chunk_length': 1.781, 'text': \"Let's hear it.\", 'start_time': 16.935, 'end_time': 18.716}, {'chunk_id': 9, 'chunk_length': 1.841, 'text': 'Are you guys awake?', 'start_time': 18.716, 'end_time': 20.557}, {'chunk_id': 10, 'chunk_length': 1.76, 'text': 'Alright.', 'start_time': 20.557, 'end_time': 22.317}, {'chunk_id': 11, 'chunk_length': 4.542, 'text': 'You better be because we have a superstar guest here.', 'start_time': 22.317, 'end_time': 26.859}, {'chunk_id': 12, 'chunk_length': 2.451, 'text': 'You heard the $41 million.', 'start_time': 26.859, 'end_time': 29.31}, {'chunk_id': 13, 'chunk_length': 3.042, 'text': \"I didn't hear honestly anything that she said after that.\", 'start_time': 29.31, 'end_time': 32.352}, {'chunk_id': 14, 'chunk_length': 6.084, 'text': \"So we're going to ask for about $40 million from him by the end of this conversation.\", 'start_time': 32.352, 'end_time': 38.436}, {'chunk_id': 15, 'chunk_length': 2.181, 'text': \"But let's get started.\", 'start_time': 38.436, 'end_time': 40.617}, {'chunk_id': 16, 'chunk_length': 4.323, 'text': \"I want to introduce Vivek and Pratyush, his co-founder, who's not here.\", 'start_time': 40.617, 'end_time': 44.94}, {'chunk_id': 17, 'chunk_length': 5.923, 'text': 'We wanted to start with playing a video of what Open Hati does.', 'start_time': 44.94, 'end_time': 50.863}, {'chunk_id': 18, 'chunk_length': 4.503, 'text': 'I encourage all of you to go to the website server.ai and check it out.', 'start_time': 50.863, 'end_time': 55.366}, {'chunk_id': 19, 'chunk_length': 2.841, 'text': 'But let me start by introducing Vivek.', 'start_time': 55.366, 'end_time': 58.207}, {'chunk_id': 20, 'chunk_length': 6.042, 'text': 'Vivek is a dear friend and he is very very modest, one of the most modest guys that I know.', 'start_time': 58.207, 'end_time': 64.249}, {'chunk_id': 21, 'chunk_length': 12.285, 'text': 'But his personal journey Vivek, you got a PhD from Carnegie Mellon, you started and sold a company to Magma and Vivek and I moved back to India, we were both in the valley on the same day actually.', 'start_time': 64.249, 'end_time': 76.534}, {'chunk_id': 22, 'chunk_length': 2.301, 'text': \"And you've been in India for the last 16 years.\", 'start_time': 76.534, 'end_time': 78.835}, {'chunk_id': 23, 'chunk_length': 6.297, 'text': \"And what most people don't know is your journey at Aadhaar.\", 'start_time': 78.835, 'end_time': 85.132}, {'chunk_id': 24, 'chunk_length': 3.382, 'text': 'He spent 13 years selflessly at Aadhaar.', 'start_time': 85.132, 'end_time': 88.514}, {'chunk_id': 25, 'chunk_length': 1.181, 'text': 'Nobody would have heard of him.', 'start_time': 88.514, 'end_time': 89.695}, {'chunk_id': 26, 'chunk_length': 7.624, 'text': 'But he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.', 'start_time': 89.695, 'end_time': 97.319}, {'chunk_id': 27, 'chunk_length': 2.842, 'text': 'So please give it out.', 'start_time': 97.319, 'end_time': 100.161}, {'chunk_id': 28, 'chunk_length': 6.804, 'text': 'So honestly, when I think of selfless service, truly selfless service, I always think of the way.', 'start_time': 100.161, 'end_time': 106.965}, {'chunk_id': 29, 'chunk_length': 7.738, 'text': \"And since then he also was at AI for Bharat, which we're going to touch on with Pratyush's other co-founder.\", 'start_time': 106.965, 'end_time': 114.703}, {'chunk_id': 30, 'chunk_length': 3.161, 'text': 'Pratyush had a PhD from ETH at Zurich.', 'start_time': 114.703, 'end_time': 117.864}, {'chunk_id': 31, 'chunk_length': 8.182, 'text': 'He was at IBM Research, he was at Microsoft Research playing a key role and a faculty at IIT Madras and at AI for Bharat.', 'start_time': 117.864, 'end_time': 126.046}, {'chunk_id': 32, 'chunk_length': 2.58, 'text': \"So that's a little brief introduction about them.\", 'start_time': 126.046, 'end_time': 128.626}, {'chunk_id': 33, 'chunk_length': 2.262, 'text': 'These guys are modest, modest engineers.', 'start_time': 128.626, 'end_time': 130.888}, {'chunk_id': 34, 'chunk_length': 2.421, 'text': \"So they don't toot their own horn.\", 'start_time': 130.888, 'end_time': 133.309}, {'chunk_id': 35, 'chunk_length': 3.683, 'text': 'So forgive me for tooting their horn in this case.', 'start_time': 133.309, 'end_time': 136.992}, {'chunk_id': 36, 'chunk_length': 4.102, 'text': \"But let's jump right in about the money.\", 'start_time': 136.992, 'end_time': 141.094}, {'chunk_id': 37, 'chunk_length': 2.602, 'text': 'Funding, 41 million bucks man.', 'start_time': 141.094, 'end_time': 143.696}, {'chunk_id': 38, 'chunk_length': 2.021, 'text': \"That's a lot of money, right?\", 'start_time': 143.696, 'end_time': 145.717}, {'chunk_id': 39, 'chunk_length': 2.842, 'text': 'Every entrepreneur here is saying, what the hell did these guys do?', 'start_time': 145.717, 'end_time': 148.559}, {'chunk_id': 40, 'chunk_length': 3.002, 'text': 'What did the investors see to write such a big cheque?', 'start_time': 148.559, 'end_time': 151.561}, {'chunk_id': 41, 'chunk_length': 15.0, 'text': \"I think it's a new trend of what's going on in India I think that for the very first time I think investors have looked at you know let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's really exciting you know and I think that about you know as\", 'start_time': 151.561, 'end_time': 166.561}, {'chunk_id': 42, 'chunk_length': 11.091, 'text': \"I think it's a new trend of what's going on in India I think that for the very first time I think investors have looked at you know let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's really exciting you know and I think that about you know as\", 'start_time': 166.561, 'end_time': 177.652}, {'chunk_id': 43, 'chunk_length': 12.889, 'text': \"While I was mentioning for the past 15 years, I've been kind of working in both the digital public infrastructure and non-profit kind of things.\", 'start_time': 177.652, 'end_time': 190.541}, {'chunk_id': 44, 'chunk_length': 8.586, 'text': 'But when this whole thing of generative AI came about, we said, OK, how can I actually make a difference in this space?', 'start_time': 190.541, 'end_time': 199.127}, {'chunk_id': 45, 'chunk_length': 6.184, 'text': 'And I said, maybe this is the opportunity to actually come out and really build something.', 'start_time': 199.127, 'end_time': 205.311}, {'chunk_id': 46, 'chunk_length': 3.703, 'text': 'And the only way that we realize that we can do this actually', 'start_time': 205.311, 'end_time': 209.014}, {'chunk_id': 47, 'chunk_length': 15.0, 'text': \"in the private sector and I think that's that and then we when we went out there and we said we want to build something which is a continuation right I mean and fundamentally the question is the reason of what we want to do at Servam AI is we want to basically make generative AI\", 'start_time': 209.014, 'end_time': 224.014}, {'chunk_id': 48, 'chunk_length': 1.397, 'text': \"in the private sector and I think that's that and then we when we went out there and we said we want to build something which is a continuation right I mean and fundamentally the question is the reason of what we want to do at Servam AI is we want to basically make generative AI\", 'start_time': 224.014, 'end_time': 225.411}, {'chunk_id': 49, 'chunk_length': 15.0, 'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\", 'start_time': 225.411, 'end_time': 240.411}, {'chunk_id': 50, 'chunk_length': 15.0, 'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\", 'start_time': 240.411, 'end_time': 255.411}, {'chunk_id': 51, 'chunk_length': 0.447, 'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\", 'start_time': 255.411, 'end_time': 255.858}, {'chunk_id': 52, 'chunk_length': 9.047, 'text': 'you know in the Indian context but in the global context I think there is just there should be many many more entrepreneurs who are back to do things in India.', 'start_time': 255.858, 'end_time': 264.905}, {'chunk_id': 53, 'chunk_length': 15.0, 'text': \"I'm going to come back to the many more entrepreneurs I'm obviously going to ask you about Bhavesh's Kuthrin so we're going to come back to the question but again $41 million all of what you said you know $2 million you know that's a good amount of money for a startup which you know which has not yet built anything\", 'start_time': 264.905, 'end_time': 279.905}, {'chunk_id': 54, 'chunk_length': 4.497, 'text': \"I'm going to come back to the many more entrepreneurs I'm obviously going to ask you about Bhavesh's Kuthrin so we're going to come back to the question but again $41 million all of what you said you know $2 million you know that's a good amount of money for a startup which you know which has not yet built anything\", 'start_time': 279.905, 'end_time': 284.402}, {'chunk_id': 55, 'chunk_length': 4.692, 'text': 'What are you going to do with all this money?', 'start_time': 284.402, 'end_time': 289.094}, {'chunk_id': 56, 'chunk_length': 1.18, 'text': 'I can solve the problem.', 'start_time': 289.094, 'end_time': 290.274}, {'chunk_id': 57, 'chunk_length': 1.881, 'text': 'I can have a perfect solution for the problem.', 'start_time': 290.274, 'end_time': 292.155}, {'chunk_id': 58, 'chunk_length': 6.002, 'text': \"I think in the last week I've got lots of calls from lots of people telling me how I can do it.\", 'start_time': 292.155, 'end_time': 298.157}, {'chunk_id': 59, 'chunk_length': 0.92, 'text': 'I know you first.', 'start_time': 298.157, 'end_time': 299.077}, {'chunk_id': 60, 'chunk_length': 1.861, 'text': 'We landed in the country the same day.', 'start_time': 299.077, 'end_time': 300.938}, {'chunk_id': 61, 'chunk_length': 0.94, 'text': \"I'm in front of the queue.\", 'start_time': 300.938, 'end_time': 301.878}, {'chunk_id': 62, 'chunk_length': 7.546, 'text': 'No, but honestly, I think the key thing in this is, is to putting together an amazing team.', 'start_time': 301.878, 'end_time': 309.424}, {'chunk_id': 63, 'chunk_length': 5.703, 'text': 'And we actually have an amazing team, but believe that it is talent that will drive this kind of thing.', 'start_time': 309.424, 'end_time': 315.127}, {'chunk_id': 64, 'chunk_length': 2.881, 'text': 'And so it is, it is to get, get talent.', 'start_time': 315.127, 'end_time': 318.008}, {'chunk_id': 65, 'chunk_length': 1.701, 'text': 'And of course the other thing is compute.', 'start_time': 318.008, 'end_time': 319.709}, {'chunk_id': 66, 'chunk_length': 5.483, 'text': 'This is extremely expensive compute wise to actually do these kinds of things.', 'start_time': 319.709, 'end_time': 325.192}, {'chunk_id': 67, 'chunk_length': 5.123, 'text': 'And I think that those are the primary things that, that, you know, use this one.', 'start_time': 325.192, 'end_time': 330.315}, {'chunk_id': 68, 'chunk_length': 0.72, 'text': 'Okay.', 'start_time': 330.315, 'end_time': 331.035}, {'chunk_id': 69, 'chunk_length': 3.887, 'text': \"I'm computing in my own head as an entrepreneur.\", 'start_time': 331.035, 'end_time': 334.922}, {'chunk_id': 70, 'chunk_length': 2.341, 'text': 'Talent, okay, you have like 20, 50 people.', 'start_time': 334.922, 'end_time': 337.263}, {'chunk_id': 71, 'chunk_length': 2.201, 'text': 'How much are you paying these guys?', 'start_time': 337.263, 'end_time': 339.464}, {'chunk_id': 72, 'chunk_length': 1.921, 'text': \"You won't touch on that.\", 'start_time': 339.464, 'end_time': 341.385}, {'chunk_id': 73, 'chunk_length': 2.282, 'text': \"But let's talk about what you guys actually built.\", 'start_time': 341.385, 'end_time': 343.667}, {'chunk_id': 74, 'chunk_length': 1.32, 'text': 'What is open Hati?', 'start_time': 343.667, 'end_time': 344.987}, {'chunk_id': 75, 'chunk_length': 3.682, 'text': 'How would you explain open Hati to many people here who might not have known about it?', 'start_time': 344.987, 'end_time': 348.669}, {'chunk_id': 76, 'chunk_length': 11.354, 'text': 'So I think OpenHAPI is, so first of all, we come from, I personally come from the open source ecosystem and also from the DPI ecosystem.', 'start_time': 348.669, 'end_time': 360.023}, {'chunk_id': 77, 'chunk_length': 5.284, 'text': 'So we believe that for this to work, we need the ecosystem to be successful.', 'start_time': 360.023, 'end_time': 365.307}, {'chunk_id': 78, 'chunk_length': 3.002, 'text': 'And as a result of that, one of the first things we did was', 'start_time': 365.307, 'end_time': 368.309}, {'chunk_id': 79, 'chunk_length': 4.381, 'text': 'hey, there are these open source large language models that exist, right?', 'start_time': 368.309, 'end_time': 372.69}, {'chunk_id': 80, 'chunk_length': 10.422, 'text': 'I mean, everybody knows about the Llama family from Meta, there are others like Mistral, there are a bunch of open source, you know, large language models.', 'start_time': 372.69, 'end_time': 383.112}, {'chunk_id': 81, 'chunk_length': 7.662, 'text': 'And then we said, is there any way that they can existing open source model and teach it language skills, right?', 'start_time': 383.112, 'end_time': 390.774}, {'chunk_id': 82, 'chunk_length': 6.304, 'text': 'And that is really what we said, can we do something like that?', 'start_time': 390.774, 'end_time': 397.078}, {'chunk_id': 83, 'chunk_length': 10.408, 'text': 'And is this a relatively frugal way of actually making models work in diverse languages?', 'start_time': 397.078, 'end_time': 407.486}, {'chunk_id': 84, 'chunk_length': 7.425, 'text': 'Because the truth is still today, if you look at the amount of data and knowledge, still English dominates these things.', 'start_time': 407.486, 'end_time': 414.911}, {'chunk_id': 85, 'chunk_length': 10.126, 'text': 'And I think that how do you actually take and make it, understand Indian language, understand Indian context, and all of those things in actually an efficient way.', 'start_time': 414.911, 'end_time': 425.037}, {'chunk_id': 86, 'chunk_length': 2.082, 'text': 'And therefore this was an attempt to do that.', 'start_time': 425.037, 'end_time': 427.119}, {'chunk_id': 87, 'chunk_length': 13.768, 'text': \"And it's an open-hearted, you know, it's currently based on the LAMA 7 billion model, but we'll be releasing many more models in different languages, different sizes, and things like that as part of this series.\", 'start_time': 427.119, 'end_time': 440.887}, {'chunk_id': 88, 'chunk_length': 14.432, 'text': \"And of course, you know, we will be building further models on those and doing other things to actually, and we'll also have endpoints that people can use, but it's not, it's definitely, you know, something that can use two things.\", 'start_time': 440.887, 'end_time': 455.319}, {'chunk_id': 89, 'chunk_length': 4.843, 'text': \"And that's the essence of what is open happiness.\", 'start_time': 455.319, 'end_time': 460.162}, {'chunk_id': 90, 'chunk_length': 6.706, 'text': 'So what does it mean to people in the audience here who are either doing their own startups or a business or developers?', 'start_time': 460.162, 'end_time': 466.868}, {'chunk_id': 91, 'chunk_length': 15.0, 'text': \"how should they look at one of the important things that we are doing is we're not just building models we are also building a platform a platform for developers where you can actually use\", 'start_time': 466.868, 'end_time': 481.868}, {'chunk_id': 92, 'chunk_length': 5.548, 'text': \"how should they look at one of the important things that we are doing is we're not just building models we are also building a platform a platform for developers where you can actually use\", 'start_time': 481.868, 'end_time': 487.416}, {'chunk_id': 93, 'chunk_length': 15.0, 'text': 'a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to pull together and figure out how to deploy generative AI applications at scale and understand and evaluate their performance.', 'start_time': 487.416, 'end_time': 502.416}, {'chunk_id': 94, 'chunk_length': 2.985, 'text': 'a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to pull together and figure out how to deploy generative AI applications at scale and understand and evaluate their performance.', 'start_time': 502.416, 'end_time': 505.401}, {'chunk_id': 95, 'chunk_length': 3.081, 'text': \"And that's something that we are planning to do.\", 'start_time': 505.401, 'end_time': 508.482}, {'chunk_id': 96, 'chunk_length': 6.884, 'text': 'And this platform is, you know, in the next couple of months will be coming out there, be available to developers.', 'start_time': 508.482, 'end_time': 515.366}, {'chunk_id': 97, 'chunk_length': 5.643, 'text': 'But of course, those who want to start with the open source things and act with that, of course, please go ahead.', 'start_time': 515.366, 'end_time': 521.009}, {'chunk_id': 98, 'chunk_length': 2.481, 'text': \"That's phenomenal.\", 'start_time': 521.009, 'end_time': 523.49}, {'chunk_id': 99, 'chunk_length': 4.803, 'text': 'How does it compare to OpenAI itself or Google?', 'start_time': 523.49, 'end_time': 528.293}, {'chunk_id': 100, 'chunk_length': 4.874, 'text': 'See, at least the things that we are doing now, right?', 'start_time': 528.293, 'end_time': 533.167}, {'chunk_id': 101, 'chunk_length': 14.972, 'text': 'I mean, one of the things that when we thought about building server, we said we want to build a full stack general API company and different people and our understanding of stack is that we need to know how to train models from scratch.', 'start_time': 533.167, 'end_time': 548.139}, {'chunk_id': 102, 'chunk_length': 5.344, 'text': 'We need to know how to kind of figure out how to deploy models to solve real world mistakes.', 'start_time': 548.139, 'end_time': 553.483}, {'chunk_id': 103, 'chunk_length': 8.861, 'text': 'And we need to play in the ecosystem to make sure that we can actually deploy population scale applications.', 'start_time': 553.483, 'end_time': 562.344}, {'chunk_id': 104, 'chunk_length': 2.501, 'text': 'So we were thinking about all of these things.', 'start_time': 562.344, 'end_time': 564.845}, {'chunk_id': 105, 'chunk_length': 4.543, 'text': 'But still the models we were talking about are fairly small models.', 'start_time': 564.845, 'end_time': 569.388}, {'chunk_id': 106, 'chunk_length': 1.12, 'text': 'They are fairly small models.', 'start_time': 569.388, 'end_time': 570.508}, {'chunk_id': 107, 'chunk_length': 4.403, 'text': \"The 7 to maybe up to 70 billion kind of range we're talking about.\", 'start_time': 570.508, 'end_time': 574.911}, {'chunk_id': 108, 'chunk_length': 4.382, 'text': \"While these models like OpenAI and they're obviously much bigger.\", 'start_time': 574.911, 'end_time': 579.293}, {'chunk_id': 109, 'chunk_length': 10.667, 'text': 'But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.', 'start_time': 579.293, 'end_time': 589.96}, {'chunk_id': 110, 'chunk_length': 8.966, 'text': 'Now those models are I mean as I said you know I think that there is space for all of those things and I think as when Sridhar was talking about', 'start_time': 589.96, 'end_time': 598.926}, {'chunk_id': 111, 'chunk_length': 15.0, 'text': \"earlier in the day, we believe that these smaller models can do many many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas and so therefore the value of these kinds of things, we are not aiming in these more set of models to build any AGI, that's not our goal.\", 'start_time': 598.926, 'end_time': 613.926}, {'chunk_id': 112, 'chunk_length': 9.324, 'text': \"earlier in the day, we believe that these smaller models can do many many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas and so therefore the value of these kinds of things, we are not aiming in these more set of models to build any AGI, that's not our goal.\", 'start_time': 613.926, 'end_time': 623.25}, {'chunk_id': 113, 'chunk_length': 11.71, 'text': 'Our goal is to make things that work extremely well for domain specific use cases or increase accessibility to language and obviously all of this unique to India.', 'start_time': 623.25, 'end_time': 634.96}, {'chunk_id': 114, 'chunk_length': 1.481, 'text': 'What is unique about India?', 'start_time': 634.96, 'end_time': 636.441}, {'chunk_id': 115, 'chunk_length': 10.569, 'text': 'Is there anything special in our ecosystem that makes small models focused with Indian languages more suited for our problems?', 'start_time': 636.441, 'end_time': 647.01}, {'chunk_id': 116, 'chunk_length': 6.248, 'text': 'So I think that, I mean, there are quite a few things that are unique about India, right?', 'start_time': 647.01, 'end_time': 653.258}, {'chunk_id': 117, 'chunk_length': 4.545, 'text': 'The first thing is I think that we are a voice first nations.', 'start_time': 653.258, 'end_time': 657.803}, {'chunk_id': 118, 'chunk_length': 3.564, 'text': 'Therefore, I think voice has to be the core to doing things.', 'start_time': 657.803, 'end_time': 661.367}, {'chunk_id': 119, 'chunk_length': 8.698, 'text': 'The other thing, of course, India is a cost-conscious country from a cost perspective.', 'start_time': 661.367, 'end_time': 670.065}, {'chunk_id': 120, 'chunk_length': 8.645, 'text': 'I would say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application.', 'start_time': 670.065, 'end_time': 678.71}, {'chunk_id': 121, 'chunk_length': 6.444, 'text': 'But when you want to scale things to a massive level and make it work, then you have to figure out how small amounts work.', 'start_time': 678.71, 'end_time': 685.154}, {'chunk_id': 122, 'chunk_length': 3.122, 'text': \"So that's something that is also specific to India.\", 'start_time': 685.154, 'end_time': 688.276}, {'chunk_id': 123, 'chunk_length': 7.505, 'text': 'The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.', 'start_time': 688.276, 'end_time': 695.781}, {'chunk_id': 124, 'chunk_length': 12.087, 'text': 'When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.', 'start_time': 695.781, 'end_time': 707.868}, {'chunk_id': 125, 'chunk_length': 0.981, 'text': \"That's a phenomenal point.\", 'start_time': 707.868, 'end_time': 708.849}, {'chunk_id': 126, 'chunk_length': 2.942, 'text': \"Like, you know, it's like DPI to the power of AI almost in some ways.\", 'start_time': 708.849, 'end_time': 711.791}, {'chunk_id': 127, 'chunk_length': 3.962, 'text': \"It's a part of Adhar, building Adhar, no better person than you.\", 'start_time': 711.791, 'end_time': 715.753}, {'chunk_id': 128, 'chunk_length': 13.124, 'text': 'So, in summary what I am hearing is small models specialized with trained with big specific language data suited for Indian problems at a compelling cost point will be suited for us.', 'start_time': 715.753, 'end_time': 728.877}, {'chunk_id': 129, 'chunk_length': 3.864, 'text': 'We are not solving some world or some complex problem.', 'start_time': 728.877, 'end_time': 732.741}, {'chunk_id': 130, 'chunk_length': 0.501, 'text': 'We are solving', 'start_time': 732.741, 'end_time': 733.242}, {'chunk_id': 131, 'chunk_length': 15.0, 'text': \"basic problems specifically focus with on voice of multiple languages that is what you see as the future am I paraphrasing this correctly no yeah so I think that certainly I mean a voice at Indian languages are an important part of our strategy but we will be building you know custom models to solve various other kinds of problems as well right it's not just limited to I think in different domains\", 'start_time': 733.242, 'end_time': 748.242}, {'chunk_id': 132, 'chunk_length': 8.851, 'text': \"basic problems specifically focus with on voice of multiple languages that is what you see as the future am I paraphrasing this correctly no yeah so I think that certainly I mean a voice at Indian languages are an important part of our strategy but we will be building you know custom models to solve various other kinds of problems as well right it's not just limited to I think in different domains\", 'start_time': 748.242, 'end_time': 757.093}, {'chunk_id': 133, 'chunk_length': 5.726, 'text': 'domains making building things based on unique data that enterprises have.', 'start_time': 757.093, 'end_time': 762.819}, {'chunk_id': 134, 'chunk_length': 2.182, 'text': \"So that's something.\", 'start_time': 762.819, 'end_time': 765.001}, {'chunk_id': 135, 'chunk_length': 0.741, 'text': 'Fair enough.', 'start_time': 765.001, 'end_time': 765.742}, {'chunk_id': 136, 'chunk_length': 5.346, 'text': 'So coming back to the elephant in the room, no pun intended with open Hati.', 'start_time': 765.742, 'end_time': 771.088}, {'chunk_id': 137, 'chunk_length': 2.743, 'text': 'What about Bhavesh Atirwal and Kruthiram?', 'start_time': 771.088, 'end_time': 773.831}, {'chunk_id': 138, 'chunk_length': 1.414, 'text': 'What is your take on it?', 'start_time': 773.831, 'end_time': 775.245}, {'chunk_id': 139, 'chunk_length': 1.041, 'text': \"I think it's great.\", 'start_time': 775.245, 'end_time': 776.286}, {'chunk_id': 140, 'chunk_length': 1.901, 'text': \"I think it's wonderful, right?\", 'start_time': 776.286, 'end_time': 778.187}, {'chunk_id': 141, 'chunk_length': 7.305, 'text': 'I mean the fact that the technology, AI is so important that we need multiple people working on it.', 'start_time': 778.187, 'end_time': 785.492}, {'chunk_id': 142, 'chunk_length': 6.024, 'text': 'The fact that there are other people thinking is actually validates that this is an important problem to be solved.', 'start_time': 785.492, 'end_time': 791.516}, {'chunk_id': 143, 'chunk_length': 5.82, 'text': 'And I think that we need everybody to come together and do that.', 'start_time': 791.516, 'end_time': 797.336}, {'chunk_id': 144, 'chunk_length': 1.642, 'text': 'So I really welcome that.', 'start_time': 797.336, 'end_time': 798.978}, {'chunk_id': 145, 'chunk_length': 1.041, 'text': \"I think it's great.\", 'start_time': 798.978, 'end_time': 800.019}, {'chunk_id': 146, 'chunk_length': 6.146, 'text': 'And I think that there will be different people will have different takes as to how to solve this kind of problem.', 'start_time': 800.019, 'end_time': 806.165}, {'chunk_id': 147, 'chunk_length': 4.244, 'text': 'And hopefully as a result of that, the entire ecosystem benefits.', 'start_time': 806.165, 'end_time': 810.409}, {'chunk_id': 148, 'chunk_length': 5.787, 'text': 'I have one more question and then I want to talk about some of the predictions that you boldly made.', 'start_time': 810.409, 'end_time': 816.196}, {'chunk_id': 149, 'chunk_length': 4.301, 'text': 'So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges.', 'start_time': 816.196, 'end_time': 820.497}, {'chunk_id': 150, 'chunk_length': 3.441, 'text': 'I ask Vivek, what do you think is going to happen by December 2024?', 'start_time': 820.497, 'end_time': 823.938}, {'chunk_id': 151, 'chunk_length': 3.961, 'text': 'What do you think sitting in this room one year later we can expect?', 'start_time': 823.938, 'end_time': 827.899}, {'chunk_id': 152, 'chunk_length': 1.94, 'text': 'And he made three bold predictions.', 'start_time': 827.899, 'end_time': 829.839}, {'chunk_id': 153, 'chunk_length': 1.741, 'text': 'So I want to talk about that.', 'start_time': 829.839, 'end_time': 831.58}, {'chunk_id': 154, 'chunk_length': 1.36, 'text': 'Before that I have one last question.', 'start_time': 831.58, 'end_time': 832.94}, {'chunk_id': 155, 'chunk_length': 5.044, 'text': 'What are the top three applications that you think are relevant for India?', 'start_time': 832.94, 'end_time': 837.984}, {'chunk_id': 156, 'chunk_length': 1.521, 'text': 'You heard Sridhar talk about medical.', 'start_time': 837.984, 'end_time': 839.505}, {'chunk_id': 157, 'chunk_length': 4.924, 'text': 'Quick summary, what do you think the top three apps are for India for AI?', 'start_time': 839.505, 'end_time': 844.429}, {'chunk_id': 158, 'chunk_length': 10.628, 'text': 'So I mean I think that as I said things like education and medical are clearly areas where I think that can be leveraged.', 'start_time': 844.429, 'end_time': 855.057}, {'chunk_id': 159, 'chunk_length': 1.401, 'text': 'The whole idea of', 'start_time': 855.057, 'end_time': 856.458}, {'chunk_id': 160, 'chunk_length': 5.863, 'text': 'or these kind of the DPI aspect of it is another major application where things can happen.', 'start_time': 856.458, 'end_time': 862.321}, {'chunk_id': 161, 'chunk_length': 2.261, 'text': \"And here I'm talking about country specific work.\", 'start_time': 862.321, 'end_time': 864.582}, {'chunk_id': 162, 'chunk_length': 5.403, 'text': 'And I think the whole idea which you also talked about was the concept of software, right?', 'start_time': 864.582, 'end_time': 869.985}, {'chunk_id': 163, 'chunk_length': 6.184, 'text': 'And I think that and clearly we have a very large software industry and how to reimagine those things.', 'start_time': 869.985, 'end_time': 876.169}, {'chunk_id': 164, 'chunk_length': 1.961, 'text': \"This context is also something that's coming.\", 'start_time': 876.169, 'end_time': 878.13}, {'chunk_id': 165, 'chunk_length': 1.881, 'text': 'Fair enough.', 'start_time': 878.13, 'end_time': 880.011}, {'chunk_id': 166, 'chunk_length': 3.642, 'text': \"Are you guys ready for Vivek Radwan's bold predictions?\", 'start_time': 880.011, 'end_time': 883.653}, {'chunk_id': 167, 'chunk_length': 1.241, 'text': 'Yeah?', 'start_time': 883.653, 'end_time': 884.894}, {'chunk_id': 168, 'chunk_length': 15.0, 'text': \"no I'm not hearing any yes this is like a big deal he's like one of the smartest guys that I know he wants to make three predictions you don't want to hear it all right so I asked him what do you think you know here later what what do you think we can expect and he came up with three things and usually people give very blah answers when they ask questions like this because they don't want to be caught wrong not be vague, vague is bold so he basically said three things and I want to list out the three things and then\", 'start_time': 884.894, 'end_time': 899.894}, {'chunk_id': 169, 'chunk_length': 11.832, 'text': \"no I'm not hearing any yes this is like a big deal he's like one of the smartest guys that I know he wants to make three predictions you don't want to hear it all right so I asked him what do you think you know here later what what do you think we can expect and he came up with three things and usually people give very blah answers when they ask questions like this because they don't want to be caught wrong not be vague, vague is bold so he basically said three things and I want to list out the three things and then\", 'start_time': 899.894, 'end_time': 911.726}, {'chunk_id': 170, 'chunk_length': 1.374, 'text': 'ask him about it.', 'start_time': 911.726, 'end_time': 913.1}, {'chunk_id': 171, 'chunk_length': 8.226, 'text': 'So number one he says I would prefer to talk to an automated customer service than a real person because they give me a better answer.', 'start_time': 913.1, 'end_time': 921.326}, {'chunk_id': 172, 'chunk_length': 2.262, 'text': \"That is Vivek Ragwan's prediction number one.\", 'start_time': 921.326, 'end_time': 923.588}, {'chunk_id': 173, 'chunk_length': 9.067, 'text': 'So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.', 'start_time': 923.588, 'end_time': 932.655}, {'chunk_id': 174, 'chunk_length': 1.121, 'text': 'He thinks there will be too much GPU.', 'start_time': 932.655, 'end_time': 933.776}, {'chunk_id': 175, 'chunk_length': 4.02, 'text': \"So, if you want a short in-media stock, it's a good time.\", 'start_time': 933.776, 'end_time': 937.796}, {'chunk_id': 176, 'chunk_length': 6.366, 'text': 'And number 3, which was extremely unexpected, he said some companies will suddenly die.', 'start_time': 937.796, 'end_time': 944.162}, {'chunk_id': 177, 'chunk_length': 3.619, 'text': 'not what I expected.', 'start_time': 944.162, 'end_time': 947.781}, {'chunk_id': 178, 'chunk_length': 9.027, 'text': \"So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the audience questions.\", 'start_time': 947.781, 'end_time': 956.808}, {'chunk_id': 179, 'chunk_length': 6.946, 'text': \"So I don't think I quite said it the way that Walai was kind of pointing, but it's interesting.\", 'start_time': 956.808, 'end_time': 963.754}, {'chunk_id': 180, 'chunk_length': 8.467, 'text': \"But I think the first thing that we said is I think that, and I don't think that this, I think there will come a time\", 'start_time': 963.754, 'end_time': 972.221}, {'chunk_id': 181, 'chunk_length': 5.425, 'text': 'when you know in areas of customer service etc.', 'start_time': 972.221, 'end_time': 977.646}, {'chunk_id': 182, 'chunk_length': 2.706, 'text': 'when you want to do something very specific.', 'start_time': 977.646, 'end_time': 980.352}, {'chunk_id': 183, 'chunk_length': 10.528, 'text': \"Today, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or you're extremely upset that you're talking to a bot.\", 'start_time': 980.352, 'end_time': 990.88}, {'chunk_id': 184, 'chunk_length': 13.766, 'text': \"But I think that there will come a time, and I'm predicting this sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that people talk to,\", 'start_time': 990.88, 'end_time': 1004.646}, {'chunk_id': 185, 'chunk_length': 15.0, 'text': \"could give and I think that that's just I just said that there will come a time where you know it's not a human you're talking to but it's probably more likely to solve your intent that's just something that that that I think that could happen okay definitely controversial but we let it go what about the GPU glut\", 'start_time': 1004.646, 'end_time': 1019.646}, {'chunk_id': 186, 'chunk_length': 7.85, 'text': \"could give and I think that that's just I just said that there will come a time where you know it's not a human you're talking to but it's probably more likely to solve your intent that's just something that that that I think that could happen okay definitely controversial but we let it go what about the GPU glut\", 'start_time': 1019.646, 'end_time': 1027.496}, {'chunk_id': 187, 'chunk_length': 13.153, 'text': 'I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go.', 'start_time': 1027.496, 'end_time': 1040.649}, {'chunk_id': 188, 'chunk_length': 13.708, 'text': 'I think the fact that there was such a severe shortage last year basically caused a number of different players to ramp up in various kinds of forms and I think that will always go in cycles.', 'start_time': 1040.649, 'end_time': 1054.357}, {'chunk_id': 189, 'chunk_length': 5.544, 'text': 'But we may find out that there are many more interesting problems that people will be able to solve.', 'start_time': 1054.357, 'end_time': 1059.901}, {'chunk_id': 190, 'chunk_length': 15.0, 'text': 'I still remember, you know, we were at a JNEI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundred?', 'start_time': 1059.901, 'end_time': 1074.901}, {'chunk_id': 191, 'chunk_length': 0.392, 'text': 'I still remember, you know, we were at a JNEI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundred?', 'start_time': 1074.901, 'end_time': 1075.293}, {'chunk_id': 192, 'chunk_length': 1.261, 'text': 'This was the question that I had asked.', 'start_time': 1075.293, 'end_time': 1076.554}, {'chunk_id': 193, 'chunk_length': 1.281, 'text': 'And nobody in the room.', 'start_time': 1076.554, 'end_time': 1077.835}, {'chunk_id': 194, 'chunk_length': 2.102, 'text': 'And these are all extremely enthusiastic JNEI people.', 'start_time': 1077.835, 'end_time': 1079.937}, {'chunk_id': 195, 'chunk_length': 1.515, 'text': 'And nobody had access.', 'start_time': 1079.937, 'end_time': 1081.452}, {'chunk_id': 196, 'chunk_length': 1.961, 'text': 'And I think that thing is going to change.', 'start_time': 1081.452, 'end_time': 1083.413}, {'chunk_id': 197, 'chunk_length': 2.021, 'text': 'You will be able to get these kinds of things.', 'start_time': 1083.413, 'end_time': 1085.434}, {'chunk_id': 198, 'chunk_length': 9.124, 'text': 'And people who want to hack and do things will have access to these things without having to write a check.', 'start_time': 1085.434, 'end_time': 1094.558}, {'chunk_id': 199, 'chunk_length': 2.181, 'text': 'Vivek is also a semiconductor guy.', 'start_time': 1094.558, 'end_time': 1096.739}, {'chunk_id': 200, 'chunk_length': 1.061, 'text': 'Before he went into Adar.', 'start_time': 1096.739, 'end_time': 1097.8}, {'chunk_id': 201, 'chunk_length': 2.521, 'text': 'So I would take his predictions very seriously.', 'start_time': 1097.8, 'end_time': 1100.321}, {'chunk_id': 202, 'chunk_length': 1.1, 'text': \"So I don't know what I would do.\", 'start_time': 1100.321, 'end_time': 1101.421}, {'chunk_id': 203, 'chunk_length': 1.221, 'text': 'I would sell my previous stock.', 'start_time': 1101.421, 'end_time': 1102.642}, {'chunk_id': 204, 'chunk_length': 1.901, 'text': 'I would not do that.', 'start_time': 1102.642, 'end_time': 1104.543}, {'chunk_id': 205, 'chunk_length': 1.42, 'text': \"But that's not what I said.\", 'start_time': 1104.543, 'end_time': 1105.963}, {'chunk_id': 206, 'chunk_length': 3.102, 'text': \"I don't want to blame you for this.\", 'start_time': 1105.963, 'end_time': 1109.065}, {'chunk_id': 207, 'chunk_length': 3.385, 'text': 'But the third one is pretty strange.', 'start_time': 1109.065, 'end_time': 1112.45}, {'chunk_id': 208, 'chunk_length': 2.507, 'text': 'Companies are born, companies die.', 'start_time': 1112.45, 'end_time': 1114.957}, {'chunk_id': 209, 'chunk_length': 2.686, 'text': 'But you said some companies will suddenly die.', 'start_time': 1114.957, 'end_time': 1117.643}, {'chunk_id': 210, 'chunk_length': 1.04, 'text': 'What does that mean?', 'start_time': 1117.643, 'end_time': 1118.683}, {'chunk_id': 211, 'chunk_length': 8.005, 'text': 'No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.', 'start_time': 1118.683, 'end_time': 1126.688}, {'chunk_id': 212, 'chunk_length': 2.362, 'text': 'AI is a tool, right?', 'start_time': 1126.688, 'end_time': 1129.05}, {'chunk_id': 213, 'chunk_length': 1.341, 'text': 'And you have to use that.', 'start_time': 1129.05, 'end_time': 1130.391}, {'chunk_id': 214, 'chunk_length': 4.102, 'text': 'And you have to use that within your business process, right?', 'start_time': 1130.391, 'end_time': 1134.493}, {'chunk_id': 215, 'chunk_length': 1.941, 'text': 'And how AI is being used.', 'start_time': 1134.493, 'end_time': 1136.434}, {'chunk_id': 216, 'chunk_length': 10.687, 'text': \"And so, and what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI\", 'start_time': 1136.434, 'end_time': 1147.121}, {'chunk_id': 217, 'chunk_length': 4.204, 'text': \"will be more effective than those who don't leverage AI.\", 'start_time': 1147.121, 'end_time': 1151.325}, {'chunk_id': 218, 'chunk_length': 2.782, 'text': 'And that will speak for organizations also.', 'start_time': 1151.325, 'end_time': 1154.107}, {'chunk_id': 219, 'chunk_length': 8.686, 'text': \"Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't.\", 'start_time': 1154.107, 'end_time': 1162.793}, {'chunk_id': 220, 'chunk_length': 1.141, 'text': \"And I think that's the thing.\", 'start_time': 1162.793, 'end_time': 1163.934}, {'chunk_id': 221, 'chunk_length': 6.244, 'text': \"And you won't know the difference until one day it becomes too obvious and it will be too late.\", 'start_time': 1163.934, 'end_time': 1170.178}, {'chunk_id': 222, 'chunk_length': 6.405, 'text': \"And I think that's the reason why everybody needs to think about what it means for your business.\", 'start_time': 1170.178, 'end_time': 1176.583}, {'chunk_id': 223, 'chunk_length': 2.581, 'text': 'Because everything will be fine.', 'start_time': 1176.583, 'end_time': 1179.164}, {'chunk_id': 224, 'chunk_length': 11.684, 'text': 'Everything will be fine and one day somebody in your either competitor in your space or something brand new coming into your space will be reimagining your business process completely.', 'start_time': 1179.164, 'end_time': 1190.848}, {'chunk_id': 225, 'chunk_length': 5.562, 'text': \"And at that stage you will find that it's a very big, very tall business.\", 'start_time': 1190.848, 'end_time': 1196.41}, {'chunk_id': 226, 'chunk_length': 13.186, 'text': \"you know mountain to climb and that's why I think it's important for both people and entities to think about how they will you know they will upgrade themselves or they will modify their first system.\", 'start_time': 1196.41, 'end_time': 1209.596}, {'chunk_id': 227, 'chunk_length': 7.044, 'text': \"That's a very nuanced answer everybody here running a business should really think about it because life will be the same\", 'start_time': 1209.596, 'end_time': 1216.64}, {'chunk_id': 228, 'chunk_length': 3.976, 'text': 'And then suddenly, suddenly something will be a step change.', 'start_time': 1216.64, 'end_time': 1220.616}, {'chunk_id': 229, 'chunk_length': 4.562, 'text': \"Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you.\", 'start_time': 1220.616, 'end_time': 1225.178}, {'chunk_id': 230, 'chunk_length': 1.801, 'text': 'So how are we doing on time?', 'start_time': 1225.178, 'end_time': 1226.979}, {'chunk_id': 231, 'chunk_length': 1.601, 'text': 'OK.', 'start_time': 1226.979, 'end_time': 1228.58}, {'chunk_id': 232, 'chunk_length': 2.441, 'text': \"So that's OK.\", 'start_time': 1228.58, 'end_time': 1231.021}, {'chunk_id': 233, 'chunk_length': 1.64, 'text': \"A lot of questions, so I'd love to.\", 'start_time': 1231.021, 'end_time': 1232.661}, {'chunk_id': 234, 'chunk_length': 1.661, 'text': 'Is there a mic that we can?', 'start_time': 1232.661, 'end_time': 1234.322}, {'chunk_id': 235, 'chunk_length': 6.563, 'text': 'Thank you.', 'start_time': 1234.322, 'end_time': 1240.885}, {'chunk_id': 236, 'chunk_length': 1.14, 'text': 'My name is Karthik.', 'start_time': 1240.885, 'end_time': 1242.025}, {'chunk_id': 237, 'chunk_length': 3.882, 'text': 'I work for IT service industry.', 'start_time': 1242.025, 'end_time': 1245.907}, {'chunk_id': 238, 'chunk_length': 15.0, 'text': \"so you're saying that you're working on LLM sorry fine-tuned LLM on top of lama my basic question fundamental question is we don't have a foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about\", 'start_time': 1245.907, 'end_time': 1260.907}, {'chunk_id': 239, 'chunk_length': 6.37, 'text': \"so you're saying that you're working on LLM sorry fine-tuned LLM on top of lama my basic question fundamental question is we don't have a foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about\", 'start_time': 1260.907, 'end_time': 1267.277}, {'chunk_id': 240, 'chunk_length': 2.84, 'text': 'tokenizers and things like that.', 'start_time': 1267.277, 'end_time': 1270.117}, {'chunk_id': 241, 'chunk_length': 7.482, 'text': 'So are you working on anything like that or you want to use mostly the existing models and run on top of it?', 'start_time': 1270.117, 'end_time': 1277.599}, {'chunk_id': 242, 'chunk_length': 1.101, 'text': 'Good question.', 'start_time': 1277.599, 'end_time': 1278.7}, {'chunk_id': 243, 'chunk_length': 1.9, 'text': 'You asked a cherry question for us.', 'start_time': 1278.7, 'end_time': 1280.6}, {'chunk_id': 244, 'chunk_length': 9.544, 'text': 'No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things that we actually built', 'start_time': 1280.6, 'end_time': 1290.144}, {'chunk_id': 245, 'chunk_length': 15.0, 'text': \"a customized tokenizer which actually fundamentally changes the cost of some of these generations in India languages and I think that we are not just we are actually we are leveraging the existing training but we are doing what's known as continual pre-training which actually but having said that you know I think that once we have to figure out where is the data to train an extremely large model from scratch and some of those things are things which will happen\", 'start_time': 1290.144, 'end_time': 1305.144}, {'chunk_id': 246, 'chunk_length': 13.737, 'text': \"a customized tokenizer which actually fundamentally changes the cost of some of these generations in India languages and I think that we are not just we are actually we are leveraging the existing training but we are doing what's known as continual pre-training which actually but having said that you know I think that once we have to figure out where is the data to train an extremely large model from scratch and some of those things are things which will happen\", 'start_time': 1305.144, 'end_time': 1318.881}, {'chunk_id': 247, 'chunk_length': 1.52, 'text': 'over time.', 'start_time': 1318.881, 'end_time': 1320.401}, {'chunk_id': 248, 'chunk_length': 6.223, 'text': 'But I think that yes, I think that we will be doing various kinds of things.', 'start_time': 1320.401, 'end_time': 1326.624}, {'chunk_id': 249, 'chunk_length': 7.723, 'text': 'But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?', 'start_time': 1326.624, 'end_time': 1334.347}, {'chunk_id': 250, 'chunk_length': 3.381, 'text': \"And that's the problem that we think we have solved.\", 'start_time': 1334.347, 'end_time': 1337.728}, {'chunk_id': 251, 'chunk_length': 2.701, 'text': \"And it's going to be the heart of this.\", 'start_time': 1337.728, 'end_time': 1340.429}, {'chunk_id': 252, 'chunk_length': 2.681, 'text': \"It's extremely well explained in the blog, even I could understand.\", 'start_time': 1340.429, 'end_time': 1343.11}, {'chunk_id': 253, 'chunk_length': 3.321, 'text': \"Hi, I'm Prashanth.\", 'start_time': 1343.11, 'end_time': 1346.431}, {'chunk_id': 254, 'chunk_length': 1.361, 'text': 'I work for a fintech company.', 'start_time': 1346.431, 'end_time': 1347.792}, {'chunk_id': 255, 'chunk_length': 10.862, 'text': 'My question is like, unlike China, we never had a consumer facing application coming out from India and in web one, web two, crypto and on.', 'start_time': 1347.792, 'end_time': 1358.654}, {'chunk_id': 256, 'chunk_length': 5.481, 'text': 'Why do you think it would be different this time in like AI?', 'start_time': 1358.654, 'end_time': 1364.135}, {'chunk_id': 257, 'chunk_length': 8.703, 'text': 'Because will the DPI and other things will serve the same purpose what the Great Firewall did in China?', 'start_time': 1364.135, 'end_time': 1372.838}, {'chunk_id': 258, 'chunk_length': 4.521, 'text': 'Or do you think like, because AI is a strategic sector,', 'start_time': 1372.838, 'end_time': 1377.359}, {'chunk_id': 259, 'chunk_length': 7.817, 'text': 'no outside country can work in NASA projects, maybe all government content will go to them.', 'start_time': 1377.359, 'end_time': 1385.176}, {'chunk_id': 260, 'chunk_length': 3.364, 'text': 'What is at least the mode here for any income?', 'start_time': 1385.176, 'end_time': 1388.54}, {'chunk_id': 261, 'chunk_length': 6.909, 'text': 'So, I think the question is,', 'start_time': 1388.54, 'end_time': 1395.449}, {'chunk_id': 262, 'chunk_length': 15.0, 'text': \"I don't know the answer to these questions right I mean I think that it's difficult to predict but I do believe and as I am repeating that the combinatorial effect of reusing Gen AI at a large scale in addition in along with the DPI work that we have done in India\", 'start_time': 1395.449, 'end_time': 1410.449}, {'chunk_id': 263, 'chunk_length': 3.028, 'text': \"I don't know the answer to these questions right I mean I think that it's difficult to predict but I do believe and as I am repeating that the combinatorial effect of reusing Gen AI at a large scale in addition in along with the DPI work that we have done in India\", 'start_time': 1410.449, 'end_time': 1413.477}, {'chunk_id': 264, 'chunk_length': 15.0, 'text': \"will have people and I and I think that in the end it is the intent is that people need to be able to use it and they will vote by things that are useful for them and if that doesn't happen you're right that that I think that we have to figure out what is the mechanism of delivery of apps right I mean how where do Indians consume\", 'start_time': 1413.477, 'end_time': 1428.477}, {'chunk_id': 265, 'chunk_length': 6.867, 'text': \"will have people and I and I think that in the end it is the intent is that people need to be able to use it and they will vote by things that are useful for them and if that doesn't happen you're right that that I think that we have to figure out what is the mechanism of delivery of apps right I mean how where do Indians consume\", 'start_time': 1428.477, 'end_time': 1435.344}, {'chunk_id': 266, 'chunk_length': 3.826, 'text': 'I am so sorry, but we are out of time.', 'start_time': 1435.344, 'end_time': 1439.17}, {'chunk_id': 267, 'chunk_length': 1.38, 'text': 'Vivek will be outside.', 'start_time': 1439.17, 'end_time': 1440.55}, {'chunk_id': 268, 'chunk_length': 2.701, 'text': 'So he will be able to answer the question.', 'start_time': 1440.55, 'end_time': 1443.251}, {'chunk_id': 269, 'chunk_length': 1.161, 'text': 'We have time for one last question.', 'start_time': 1443.251, 'end_time': 1444.412}, {'chunk_id': 270, 'chunk_length': 1.76, 'text': 'Can I just take one last?', 'start_time': 1444.412, 'end_time': 1446.172}, {'chunk_id': 271, 'chunk_length': 0.24, 'text': 'Yeah.', 'start_time': 1446.172, 'end_time': 1446.412}, {'chunk_id': 272, 'chunk_length': 1.081, 'text': 'Thank you.', 'start_time': 1446.412, 'end_time': 1447.493}, {'chunk_id': 273, 'chunk_length': 0.44, 'text': 'Thank you.', 'start_time': 1447.493, 'end_time': 1447.933}, {'chunk_id': 274, 'chunk_length': 1.04, 'text': 'I am Manish Kothari.', 'start_time': 1447.933, 'end_time': 1448.973}, {'chunk_id': 275, 'chunk_length': 1.681, 'text': 'I am from ISBR Business School.', 'start_time': 1448.973, 'end_time': 1450.654}, {'chunk_id': 276, 'chunk_length': 2.221, 'text': 'Good that I got a chance to ask you this question.', 'start_time': 1450.654, 'end_time': 1452.875}, {'chunk_id': 277, 'chunk_length': 4.902, 'text': 'During lunchtime, there were a few of our educationists whom we were talking about.', 'start_time': 1452.875, 'end_time': 1457.777}, {'chunk_id': 278, 'chunk_length': 3.661, 'text': 'There was one from school and we are from the MBA institutions.', 'start_time': 1457.777, 'end_time': 1461.438}, {'chunk_id': 279, 'chunk_length': 2.461, 'text': 'We were thinking of these present generations.', 'start_time': 1461.438, 'end_time': 1463.899}, {'chunk_id': 280, 'chunk_length': 2.721, 'text': 'How do we get them into what you are doing?', 'start_time': 1463.899, 'end_time': 1466.62}, {'chunk_id': 281, 'chunk_length': 13.211, 'text': 'There is one thing that they have been regularly that the concentrations that they are working on but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important including the trainers who train them.', 'start_time': 1466.62, 'end_time': 1479.831}, {'chunk_id': 282, 'chunk_length': 6.353, 'text': 'Making them future ready into what you are doing is amazing and the speed that with which is growing.', 'start_time': 1479.831, 'end_time': 1486.184}, {'chunk_id': 283, 'chunk_length': 3.462, 'text': 'It is calling for a lot of training that needs to be done.', 'start_time': 1486.184, 'end_time': 1489.646}, {'chunk_id': 284, 'chunk_length': 4.864, 'text': 'Can you from your angle through some light on how we could make them future ready?', 'start_time': 1489.646, 'end_time': 1494.51}, {'chunk_id': 285, 'chunk_length': 5.724, 'text': 'How these people who are who are management graduates and from schools who are coming out?', 'start_time': 1494.51, 'end_time': 1500.234}, {'chunk_id': 286, 'chunk_length': 3.263, 'text': 'How do we get into this part of technology that you spoke about?', 'start_time': 1500.234, 'end_time': 1503.497}, {'chunk_id': 287, 'chunk_length': 15.0, 'text': 'This is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right?', 'start_time': 1503.497, 'end_time': 1518.497}, {'chunk_id': 288, 'chunk_length': 3.607, 'text': 'This is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right?', 'start_time': 1518.497, 'end_time': 1522.104}, {'chunk_id': 289, 'chunk_length': 4.382, 'text': 'There are from a core set of having people who are extremely good', 'start_time': 1522.104, 'end_time': 1526.486}, {'chunk_id': 290, 'chunk_length': 7.545, 'text': \"And there you don't need as many, but then there are vast numbers of people who can actually leverage these tools.\", 'start_time': 1526.486, 'end_time': 1534.031}, {'chunk_id': 291, 'chunk_length': 10.206, 'text': \"By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that.\", 'start_time': 1534.031, 'end_time': 1544.237}, {'chunk_id': 292, 'chunk_length': 8.003, 'text': 'And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people.', 'start_time': 1544.237, 'end_time': 1552.24}, {'chunk_id': 293, 'chunk_length': 11.004, 'text': 'And because asking the things in the right way and having the right kind of applications will make a difference in how people get used to this.', 'start_time': 1552.24, 'end_time': 1563.244}, {'chunk_id': 294, 'chunk_length': 0.16, 'text': 'Awesome.', 'start_time': 1563.244, 'end_time': 1563.404}, {'chunk_id': 295, 'chunk_length': 0.46, 'text': 'Thank you.', 'start_time': 1563.404, 'end_time': 1563.864}, {'chunk_id': 296, 'chunk_length': 1.741, 'text': 'Thank you very much Vivek.', 'start_time': 1563.864, 'end_time': 1565.605}, {'chunk_id': 297, 'chunk_length': 2.041, 'text': 'Very good luck to Sarvam and good luck to India.', 'start_time': 1565.605, 'end_time': 1567.646}, {'chunk_id': 298, 'chunk_length': 2.32, 'text': \"I think it's going to be a lot right on your shoulders.\", 'start_time': 1567.646, 'end_time': 1569.966}, {'chunk_id': 299, 'chunk_length': 1.381, 'text': 'Thanks, Vala.', 'start_time': 1569.966, 'end_time': 1571.347}, {'chunk_id': 300, 'chunk_length': 3.408, 'text': 'Thank you Mr. Raghavan.', 'start_time': 1571.347, 'end_time': 1574.755}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŒŸ Chunks of whole YT Video specified, in order with higher precision."
      ],
      "metadata": {
        "id": "xOiWlJMi1aUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lW1VvtHVjd2",
        "outputId": "ab10a200-5c17-4b92-dd7c-cb85beb6b5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'chunk_id': 1,\n",
              "  'chunk_length': 2.09,\n",
              "  'text': 'Congratulations to you Mr. Raghavan for that.',\n",
              "  'start_time': 0.0,\n",
              "  'end_time': 2.09},\n",
              " {'chunk_id': 2,\n",
              "  'chunk_length': 1.34,\n",
              "  'text': 'Thank you so much for joining us.',\n",
              "  'start_time': 2.09,\n",
              "  'end_time': 3.43},\n",
              " {'chunk_id': 3,\n",
              "  'chunk_length': 0.801,\n",
              "  'text': 'Over to you.',\n",
              "  'start_time': 3.43,\n",
              "  'end_time': 4.231},\n",
              " {'chunk_id': 4,\n",
              "  'chunk_length': 5.101,\n",
              "  'text': 'Hi everybody.',\n",
              "  'start_time': 4.231,\n",
              "  'end_time': 9.332},\n",
              " {'chunk_id': 5,\n",
              "  'chunk_length': 0.721,\n",
              "  'text': 'How are you?',\n",
              "  'start_time': 9.332,\n",
              "  'end_time': 10.053},\n",
              " {'chunk_id': 6,\n",
              "  'chunk_length': 3.501,\n",
              "  'text': 'I am not hearing this at all.',\n",
              "  'start_time': 10.053,\n",
              "  'end_time': 13.554},\n",
              " {'chunk_id': 7,\n",
              "  'chunk_length': 3.381,\n",
              "  'text': \"It's like a post-lunch energy downer or something.\",\n",
              "  'start_time': 13.554,\n",
              "  'end_time': 16.935},\n",
              " {'chunk_id': 8,\n",
              "  'chunk_length': 1.781,\n",
              "  'text': \"Let's hear it.\",\n",
              "  'start_time': 16.935,\n",
              "  'end_time': 18.716},\n",
              " {'chunk_id': 9,\n",
              "  'chunk_length': 1.841,\n",
              "  'text': 'Are you guys awake?',\n",
              "  'start_time': 18.716,\n",
              "  'end_time': 20.557},\n",
              " {'chunk_id': 10,\n",
              "  'chunk_length': 1.76,\n",
              "  'text': 'Alright.',\n",
              "  'start_time': 20.557,\n",
              "  'end_time': 22.317},\n",
              " {'chunk_id': 11,\n",
              "  'chunk_length': 4.542,\n",
              "  'text': 'You better be because we have a superstar guest here.',\n",
              "  'start_time': 22.317,\n",
              "  'end_time': 26.859},\n",
              " {'chunk_id': 12,\n",
              "  'chunk_length': 2.451,\n",
              "  'text': 'You heard the $41 million.',\n",
              "  'start_time': 26.859,\n",
              "  'end_time': 29.31},\n",
              " {'chunk_id': 13,\n",
              "  'chunk_length': 3.042,\n",
              "  'text': \"I didn't hear honestly anything that she said after that.\",\n",
              "  'start_time': 29.31,\n",
              "  'end_time': 32.352},\n",
              " {'chunk_id': 14,\n",
              "  'chunk_length': 6.084,\n",
              "  'text': \"So we're going to ask for about $40 million from him by the end of this conversation.\",\n",
              "  'start_time': 32.352,\n",
              "  'end_time': 38.436},\n",
              " {'chunk_id': 15,\n",
              "  'chunk_length': 2.181,\n",
              "  'text': \"But let's get started.\",\n",
              "  'start_time': 38.436,\n",
              "  'end_time': 40.617},\n",
              " {'chunk_id': 16,\n",
              "  'chunk_length': 4.323,\n",
              "  'text': \"I want to introduce Vivek and Pratyush, his co-founder, who's not here.\",\n",
              "  'start_time': 40.617,\n",
              "  'end_time': 44.94},\n",
              " {'chunk_id': 17,\n",
              "  'chunk_length': 5.923,\n",
              "  'text': 'We wanted to start with playing a video of what Open Hati does.',\n",
              "  'start_time': 44.94,\n",
              "  'end_time': 50.863},\n",
              " {'chunk_id': 18,\n",
              "  'chunk_length': 4.503,\n",
              "  'text': 'I encourage all of you to go to the website server.ai and check it out.',\n",
              "  'start_time': 50.863,\n",
              "  'end_time': 55.366},\n",
              " {'chunk_id': 19,\n",
              "  'chunk_length': 2.841,\n",
              "  'text': 'But let me start by introducing Vivek.',\n",
              "  'start_time': 55.366,\n",
              "  'end_time': 58.207},\n",
              " {'chunk_id': 20,\n",
              "  'chunk_length': 6.042,\n",
              "  'text': 'Vivek is a dear friend and he is very very modest, one of the most modest guys that I know.',\n",
              "  'start_time': 58.207,\n",
              "  'end_time': 64.249},\n",
              " {'chunk_id': 21,\n",
              "  'chunk_length': 12.285,\n",
              "  'text': 'But his personal journey Vivek, you got a PhD from Carnegie Mellon, you started and sold a company to Magma and Vivek and I moved back to India, we were both in the valley on the same day actually.',\n",
              "  'start_time': 64.249,\n",
              "  'end_time': 76.534},\n",
              " {'chunk_id': 22,\n",
              "  'chunk_length': 2.301,\n",
              "  'text': \"And you've been in India for the last 16 years.\",\n",
              "  'start_time': 76.534,\n",
              "  'end_time': 78.835},\n",
              " {'chunk_id': 23,\n",
              "  'chunk_length': 6.297,\n",
              "  'text': \"And what most people don't know is your journey at Aadhaar.\",\n",
              "  'start_time': 78.835,\n",
              "  'end_time': 85.132},\n",
              " {'chunk_id': 24,\n",
              "  'chunk_length': 3.382,\n",
              "  'text': 'He spent 13 years selflessly at Aadhaar.',\n",
              "  'start_time': 85.132,\n",
              "  'end_time': 88.514},\n",
              " {'chunk_id': 25,\n",
              "  'chunk_length': 1.181,\n",
              "  'text': 'Nobody would have heard of him.',\n",
              "  'start_time': 88.514,\n",
              "  'end_time': 89.695},\n",
              " {'chunk_id': 26,\n",
              "  'chunk_length': 7.624,\n",
              "  'text': 'But he was a pioneering technology visionary behind Aadhaar, which we all take for granted today.',\n",
              "  'start_time': 89.695,\n",
              "  'end_time': 97.319},\n",
              " {'chunk_id': 27,\n",
              "  'chunk_length': 2.842,\n",
              "  'text': 'So please give it out.',\n",
              "  'start_time': 97.319,\n",
              "  'end_time': 100.161},\n",
              " {'chunk_id': 28,\n",
              "  'chunk_length': 6.804,\n",
              "  'text': 'So honestly, when I think of selfless service, truly selfless service, I always think of the way.',\n",
              "  'start_time': 100.161,\n",
              "  'end_time': 106.965},\n",
              " {'chunk_id': 29,\n",
              "  'chunk_length': 7.738,\n",
              "  'text': \"And since then he also was at AI for Bharat, which we're going to touch on with Pratyush's other co-founder.\",\n",
              "  'start_time': 106.965,\n",
              "  'end_time': 114.703},\n",
              " {'chunk_id': 30,\n",
              "  'chunk_length': 3.161,\n",
              "  'text': 'Pratyush had a PhD from ETH at Zurich.',\n",
              "  'start_time': 114.703,\n",
              "  'end_time': 117.864},\n",
              " {'chunk_id': 31,\n",
              "  'chunk_length': 8.182,\n",
              "  'text': 'He was at IBM Research, he was at Microsoft Research playing a key role and a faculty at IIT Madras and at AI for Bharat.',\n",
              "  'start_time': 117.864,\n",
              "  'end_time': 126.046},\n",
              " {'chunk_id': 32,\n",
              "  'chunk_length': 2.58,\n",
              "  'text': \"So that's a little brief introduction about them.\",\n",
              "  'start_time': 126.046,\n",
              "  'end_time': 128.626},\n",
              " {'chunk_id': 33,\n",
              "  'chunk_length': 2.262,\n",
              "  'text': 'These guys are modest, modest engineers.',\n",
              "  'start_time': 128.626,\n",
              "  'end_time': 130.888},\n",
              " {'chunk_id': 34,\n",
              "  'chunk_length': 2.421,\n",
              "  'text': \"So they don't toot their own horn.\",\n",
              "  'start_time': 130.888,\n",
              "  'end_time': 133.309},\n",
              " {'chunk_id': 35,\n",
              "  'chunk_length': 3.683,\n",
              "  'text': 'So forgive me for tooting their horn in this case.',\n",
              "  'start_time': 133.309,\n",
              "  'end_time': 136.992},\n",
              " {'chunk_id': 36,\n",
              "  'chunk_length': 4.102,\n",
              "  'text': \"But let's jump right in about the money.\",\n",
              "  'start_time': 136.992,\n",
              "  'end_time': 141.094},\n",
              " {'chunk_id': 37,\n",
              "  'chunk_length': 2.602,\n",
              "  'text': 'Funding, 41 million bucks man.',\n",
              "  'start_time': 141.094,\n",
              "  'end_time': 143.696},\n",
              " {'chunk_id': 38,\n",
              "  'chunk_length': 2.021,\n",
              "  'text': \"That's a lot of money, right?\",\n",
              "  'start_time': 143.696,\n",
              "  'end_time': 145.717},\n",
              " {'chunk_id': 39,\n",
              "  'chunk_length': 2.842,\n",
              "  'text': 'Every entrepreneur here is saying, what the hell did these guys do?',\n",
              "  'start_time': 145.717,\n",
              "  'end_time': 148.559},\n",
              " {'chunk_id': 40,\n",
              "  'chunk_length': 3.002,\n",
              "  'text': 'What did the investors see to write such a big cheque?',\n",
              "  'start_time': 148.559,\n",
              "  'end_time': 151.561},\n",
              " {'chunk_id': 41,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"I think it's a new trend of what's going on in India I think that for the very first time I think investors have looked at you know let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's really exciting you know and I think that about you know as\",\n",
              "  'start_time': 151.561,\n",
              "  'end_time': 166.561},\n",
              " {'chunk_id': 42,\n",
              "  'chunk_length': 11.091,\n",
              "  'text': \"I think it's a new trend of what's going on in India I think that for the very first time I think investors have looked at you know let's try and build something deep tech out of the country and let's try to figure out how to build something as a foundational technology out of the country and that's really what's really exciting you know and I think that about you know as\",\n",
              "  'start_time': 166.561,\n",
              "  'end_time': 177.652},\n",
              " {'chunk_id': 43,\n",
              "  'chunk_length': 12.889,\n",
              "  'text': \"While I was mentioning for the past 15 years, I've been kind of working in both the digital public infrastructure and non-profit kind of things.\",\n",
              "  'start_time': 177.652,\n",
              "  'end_time': 190.541},\n",
              " {'chunk_id': 44,\n",
              "  'chunk_length': 8.586,\n",
              "  'text': 'But when this whole thing of generative AI came about, we said, OK, how can I actually make a difference in this space?',\n",
              "  'start_time': 190.541,\n",
              "  'end_time': 199.127},\n",
              " {'chunk_id': 45,\n",
              "  'chunk_length': 6.184,\n",
              "  'text': 'And I said, maybe this is the opportunity to actually come out and really build something.',\n",
              "  'start_time': 199.127,\n",
              "  'end_time': 205.311},\n",
              " {'chunk_id': 46,\n",
              "  'chunk_length': 3.703,\n",
              "  'text': 'And the only way that we realize that we can do this actually',\n",
              "  'start_time': 205.311,\n",
              "  'end_time': 209.014},\n",
              " {'chunk_id': 47,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"in the private sector and I think that's that and then we when we went out there and we said we want to build something which is a continuation right I mean and fundamentally the question is the reason of what we want to do at Servam AI is we want to basically make generative AI\",\n",
              "  'start_time': 209.014,\n",
              "  'end_time': 224.014},\n",
              " {'chunk_id': 48,\n",
              "  'chunk_length': 1.397,\n",
              "  'text': \"in the private sector and I think that's that and then we when we went out there and we said we want to build something which is a continuation right I mean and fundamentally the question is the reason of what we want to do at Servam AI is we want to basically make generative AI\",\n",
              "  'start_time': 224.014,\n",
              "  'end_time': 225.411},\n",
              " {'chunk_id': 49,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\",\n",
              "  'start_time': 225.411,\n",
              "  'end_time': 240.411},\n",
              " {'chunk_id': 50,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\",\n",
              "  'start_time': 240.411,\n",
              "  'end_time': 255.411},\n",
              " {'chunk_id': 51,\n",
              "  'chunk_length': 0.447,\n",
              "  'text': \"available and accessible to the people in the country and that's the intent and when we said that we want to do this there was a resonance in the investment community and I think it's a responsibility to really to show that something like this can be built out of India so we see that as confidence and a responsibility and I also hope it's a trend that there are many more people like us who are backed because if you look at it maybe it's a large number in a\",\n",
              "  'start_time': 255.411,\n",
              "  'end_time': 255.858},\n",
              " {'chunk_id': 52,\n",
              "  'chunk_length': 9.047,\n",
              "  'text': 'you know in the Indian context but in the global context I think there is just there should be many many more entrepreneurs who are back to do things in India.',\n",
              "  'start_time': 255.858,\n",
              "  'end_time': 264.905},\n",
              " {'chunk_id': 53,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"I'm going to come back to the many more entrepreneurs I'm obviously going to ask you about Bhavesh's Kuthrin so we're going to come back to the question but again $41 million all of what you said you know $2 million you know that's a good amount of money for a startup which you know which has not yet built anything\",\n",
              "  'start_time': 264.905,\n",
              "  'end_time': 279.905},\n",
              " {'chunk_id': 54,\n",
              "  'chunk_length': 4.497,\n",
              "  'text': \"I'm going to come back to the many more entrepreneurs I'm obviously going to ask you about Bhavesh's Kuthrin so we're going to come back to the question but again $41 million all of what you said you know $2 million you know that's a good amount of money for a startup which you know which has not yet built anything\",\n",
              "  'start_time': 279.905,\n",
              "  'end_time': 284.402},\n",
              " {'chunk_id': 55,\n",
              "  'chunk_length': 4.692,\n",
              "  'text': 'What are you going to do with all this money?',\n",
              "  'start_time': 284.402,\n",
              "  'end_time': 289.094},\n",
              " {'chunk_id': 56,\n",
              "  'chunk_length': 1.18,\n",
              "  'text': 'I can solve the problem.',\n",
              "  'start_time': 289.094,\n",
              "  'end_time': 290.274},\n",
              " {'chunk_id': 57,\n",
              "  'chunk_length': 1.881,\n",
              "  'text': 'I can have a perfect solution for the problem.',\n",
              "  'start_time': 290.274,\n",
              "  'end_time': 292.155},\n",
              " {'chunk_id': 58,\n",
              "  'chunk_length': 6.002,\n",
              "  'text': \"I think in the last week I've got lots of calls from lots of people telling me how I can do it.\",\n",
              "  'start_time': 292.155,\n",
              "  'end_time': 298.157},\n",
              " {'chunk_id': 59,\n",
              "  'chunk_length': 0.92,\n",
              "  'text': 'I know you first.',\n",
              "  'start_time': 298.157,\n",
              "  'end_time': 299.077},\n",
              " {'chunk_id': 60,\n",
              "  'chunk_length': 1.861,\n",
              "  'text': 'We landed in the country the same day.',\n",
              "  'start_time': 299.077,\n",
              "  'end_time': 300.938},\n",
              " {'chunk_id': 61,\n",
              "  'chunk_length': 0.94,\n",
              "  'text': \"I'm in front of the queue.\",\n",
              "  'start_time': 300.938,\n",
              "  'end_time': 301.878},\n",
              " {'chunk_id': 62,\n",
              "  'chunk_length': 7.546,\n",
              "  'text': 'No, but honestly, I think the key thing in this is, is to putting together an amazing team.',\n",
              "  'start_time': 301.878,\n",
              "  'end_time': 309.424},\n",
              " {'chunk_id': 63,\n",
              "  'chunk_length': 5.703,\n",
              "  'text': 'And we actually have an amazing team, but believe that it is talent that will drive this kind of thing.',\n",
              "  'start_time': 309.424,\n",
              "  'end_time': 315.127},\n",
              " {'chunk_id': 64,\n",
              "  'chunk_length': 2.881,\n",
              "  'text': 'And so it is, it is to get, get talent.',\n",
              "  'start_time': 315.127,\n",
              "  'end_time': 318.008},\n",
              " {'chunk_id': 65,\n",
              "  'chunk_length': 1.701,\n",
              "  'text': 'And of course the other thing is compute.',\n",
              "  'start_time': 318.008,\n",
              "  'end_time': 319.709},\n",
              " {'chunk_id': 66,\n",
              "  'chunk_length': 5.483,\n",
              "  'text': 'This is extremely expensive compute wise to actually do these kinds of things.',\n",
              "  'start_time': 319.709,\n",
              "  'end_time': 325.192},\n",
              " {'chunk_id': 67,\n",
              "  'chunk_length': 5.123,\n",
              "  'text': 'And I think that those are the primary things that, that, you know, use this one.',\n",
              "  'start_time': 325.192,\n",
              "  'end_time': 330.315},\n",
              " {'chunk_id': 68,\n",
              "  'chunk_length': 0.72,\n",
              "  'text': 'Okay.',\n",
              "  'start_time': 330.315,\n",
              "  'end_time': 331.035},\n",
              " {'chunk_id': 69,\n",
              "  'chunk_length': 3.887,\n",
              "  'text': \"I'm computing in my own head as an entrepreneur.\",\n",
              "  'start_time': 331.035,\n",
              "  'end_time': 334.922},\n",
              " {'chunk_id': 70,\n",
              "  'chunk_length': 2.341,\n",
              "  'text': 'Talent, okay, you have like 20, 50 people.',\n",
              "  'start_time': 334.922,\n",
              "  'end_time': 337.263},\n",
              " {'chunk_id': 71,\n",
              "  'chunk_length': 2.201,\n",
              "  'text': 'How much are you paying these guys?',\n",
              "  'start_time': 337.263,\n",
              "  'end_time': 339.464},\n",
              " {'chunk_id': 72,\n",
              "  'chunk_length': 1.921,\n",
              "  'text': \"You won't touch on that.\",\n",
              "  'start_time': 339.464,\n",
              "  'end_time': 341.385},\n",
              " {'chunk_id': 73,\n",
              "  'chunk_length': 2.282,\n",
              "  'text': \"But let's talk about what you guys actually built.\",\n",
              "  'start_time': 341.385,\n",
              "  'end_time': 343.667},\n",
              " {'chunk_id': 74,\n",
              "  'chunk_length': 1.32,\n",
              "  'text': 'What is open Hati?',\n",
              "  'start_time': 343.667,\n",
              "  'end_time': 344.987},\n",
              " {'chunk_id': 75,\n",
              "  'chunk_length': 3.682,\n",
              "  'text': 'How would you explain open Hati to many people here who might not have known about it?',\n",
              "  'start_time': 344.987,\n",
              "  'end_time': 348.669},\n",
              " {'chunk_id': 76,\n",
              "  'chunk_length': 11.354,\n",
              "  'text': 'So I think OpenHAPI is, so first of all, we come from, I personally come from the open source ecosystem and also from the DPI ecosystem.',\n",
              "  'start_time': 348.669,\n",
              "  'end_time': 360.023},\n",
              " {'chunk_id': 77,\n",
              "  'chunk_length': 5.284,\n",
              "  'text': 'So we believe that for this to work, we need the ecosystem to be successful.',\n",
              "  'start_time': 360.023,\n",
              "  'end_time': 365.307},\n",
              " {'chunk_id': 78,\n",
              "  'chunk_length': 3.002,\n",
              "  'text': 'And as a result of that, one of the first things we did was',\n",
              "  'start_time': 365.307,\n",
              "  'end_time': 368.309},\n",
              " {'chunk_id': 79,\n",
              "  'chunk_length': 4.381,\n",
              "  'text': 'hey, there are these open source large language models that exist, right?',\n",
              "  'start_time': 368.309,\n",
              "  'end_time': 372.69},\n",
              " {'chunk_id': 80,\n",
              "  'chunk_length': 10.422,\n",
              "  'text': 'I mean, everybody knows about the Llama family from Meta, there are others like Mistral, there are a bunch of open source, you know, large language models.',\n",
              "  'start_time': 372.69,\n",
              "  'end_time': 383.112},\n",
              " {'chunk_id': 81,\n",
              "  'chunk_length': 7.662,\n",
              "  'text': 'And then we said, is there any way that they can existing open source model and teach it language skills, right?',\n",
              "  'start_time': 383.112,\n",
              "  'end_time': 390.774},\n",
              " {'chunk_id': 82,\n",
              "  'chunk_length': 6.304,\n",
              "  'text': 'And that is really what we said, can we do something like that?',\n",
              "  'start_time': 390.774,\n",
              "  'end_time': 397.078},\n",
              " {'chunk_id': 83,\n",
              "  'chunk_length': 10.408,\n",
              "  'text': 'And is this a relatively frugal way of actually making models work in diverse languages?',\n",
              "  'start_time': 397.078,\n",
              "  'end_time': 407.486},\n",
              " {'chunk_id': 84,\n",
              "  'chunk_length': 7.425,\n",
              "  'text': 'Because the truth is still today, if you look at the amount of data and knowledge, still English dominates these things.',\n",
              "  'start_time': 407.486,\n",
              "  'end_time': 414.911},\n",
              " {'chunk_id': 85,\n",
              "  'chunk_length': 10.126,\n",
              "  'text': 'And I think that how do you actually take and make it, understand Indian language, understand Indian context, and all of those things in actually an efficient way.',\n",
              "  'start_time': 414.911,\n",
              "  'end_time': 425.037},\n",
              " {'chunk_id': 86,\n",
              "  'chunk_length': 2.082,\n",
              "  'text': 'And therefore this was an attempt to do that.',\n",
              "  'start_time': 425.037,\n",
              "  'end_time': 427.119},\n",
              " {'chunk_id': 87,\n",
              "  'chunk_length': 13.768,\n",
              "  'text': \"And it's an open-hearted, you know, it's currently based on the LAMA 7 billion model, but we'll be releasing many more models in different languages, different sizes, and things like that as part of this series.\",\n",
              "  'start_time': 427.119,\n",
              "  'end_time': 440.887},\n",
              " {'chunk_id': 88,\n",
              "  'chunk_length': 14.432,\n",
              "  'text': \"And of course, you know, we will be building further models on those and doing other things to actually, and we'll also have endpoints that people can use, but it's not, it's definitely, you know, something that can use two things.\",\n",
              "  'start_time': 440.887,\n",
              "  'end_time': 455.319},\n",
              " {'chunk_id': 89,\n",
              "  'chunk_length': 4.843,\n",
              "  'text': \"And that's the essence of what is open happiness.\",\n",
              "  'start_time': 455.319,\n",
              "  'end_time': 460.162},\n",
              " {'chunk_id': 90,\n",
              "  'chunk_length': 6.706,\n",
              "  'text': 'So what does it mean to people in the audience here who are either doing their own startups or a business or developers?',\n",
              "  'start_time': 460.162,\n",
              "  'end_time': 466.868},\n",
              " {'chunk_id': 91,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"how should they look at one of the important things that we are doing is we're not just building models we are also building a platform a platform for developers where you can actually use\",\n",
              "  'start_time': 466.868,\n",
              "  'end_time': 481.868},\n",
              " {'chunk_id': 92,\n",
              "  'chunk_length': 5.548,\n",
              "  'text': \"how should they look at one of the important things that we are doing is we're not just building models we are also building a platform a platform for developers where you can actually use\",\n",
              "  'start_time': 481.868,\n",
              "  'end_time': 487.416},\n",
              " {'chunk_id': 93,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': 'a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to pull together and figure out how to deploy generative AI applications at scale and understand and evaluate their performance.',\n",
              "  'start_time': 487.416,\n",
              "  'end_time': 502.416},\n",
              " {'chunk_id': 94,\n",
              "  'chunk_length': 2.985,\n",
              "  'text': 'a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source, and actually to pull together and figure out how to deploy generative AI applications at scale and understand and evaluate their performance.',\n",
              "  'start_time': 502.416,\n",
              "  'end_time': 505.401},\n",
              " {'chunk_id': 95,\n",
              "  'chunk_length': 3.081,\n",
              "  'text': \"And that's something that we are planning to do.\",\n",
              "  'start_time': 505.401,\n",
              "  'end_time': 508.482},\n",
              " {'chunk_id': 96,\n",
              "  'chunk_length': 6.884,\n",
              "  'text': 'And this platform is, you know, in the next couple of months will be coming out there, be available to developers.',\n",
              "  'start_time': 508.482,\n",
              "  'end_time': 515.366},\n",
              " {'chunk_id': 97,\n",
              "  'chunk_length': 5.643,\n",
              "  'text': 'But of course, those who want to start with the open source things and act with that, of course, please go ahead.',\n",
              "  'start_time': 515.366,\n",
              "  'end_time': 521.009},\n",
              " {'chunk_id': 98,\n",
              "  'chunk_length': 2.481,\n",
              "  'text': \"That's phenomenal.\",\n",
              "  'start_time': 521.009,\n",
              "  'end_time': 523.49},\n",
              " {'chunk_id': 99,\n",
              "  'chunk_length': 4.803,\n",
              "  'text': 'How does it compare to OpenAI itself or Google?',\n",
              "  'start_time': 523.49,\n",
              "  'end_time': 528.293},\n",
              " {'chunk_id': 100,\n",
              "  'chunk_length': 4.874,\n",
              "  'text': 'See, at least the things that we are doing now, right?',\n",
              "  'start_time': 528.293,\n",
              "  'end_time': 533.167},\n",
              " {'chunk_id': 101,\n",
              "  'chunk_length': 14.972,\n",
              "  'text': 'I mean, one of the things that when we thought about building server, we said we want to build a full stack general API company and different people and our understanding of stack is that we need to know how to train models from scratch.',\n",
              "  'start_time': 533.167,\n",
              "  'end_time': 548.139},\n",
              " {'chunk_id': 102,\n",
              "  'chunk_length': 5.344,\n",
              "  'text': 'We need to know how to kind of figure out how to deploy models to solve real world mistakes.',\n",
              "  'start_time': 548.139,\n",
              "  'end_time': 553.483},\n",
              " {'chunk_id': 103,\n",
              "  'chunk_length': 8.861,\n",
              "  'text': 'And we need to play in the ecosystem to make sure that we can actually deploy population scale applications.',\n",
              "  'start_time': 553.483,\n",
              "  'end_time': 562.344},\n",
              " {'chunk_id': 104,\n",
              "  'chunk_length': 2.501,\n",
              "  'text': 'So we were thinking about all of these things.',\n",
              "  'start_time': 562.344,\n",
              "  'end_time': 564.845},\n",
              " {'chunk_id': 105,\n",
              "  'chunk_length': 4.543,\n",
              "  'text': 'But still the models we were talking about are fairly small models.',\n",
              "  'start_time': 564.845,\n",
              "  'end_time': 569.388},\n",
              " {'chunk_id': 106,\n",
              "  'chunk_length': 1.12,\n",
              "  'text': 'They are fairly small models.',\n",
              "  'start_time': 569.388,\n",
              "  'end_time': 570.508},\n",
              " {'chunk_id': 107,\n",
              "  'chunk_length': 4.403,\n",
              "  'text': \"The 7 to maybe up to 70 billion kind of range we're talking about.\",\n",
              "  'start_time': 570.508,\n",
              "  'end_time': 574.911},\n",
              " {'chunk_id': 108,\n",
              "  'chunk_length': 4.382,\n",
              "  'text': \"While these models like OpenAI and they're obviously much bigger.\",\n",
              "  'start_time': 574.911,\n",
              "  'end_time': 579.293},\n",
              " {'chunk_id': 109,\n",
              "  'chunk_length': 10.667,\n",
              "  'text': 'But we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people.',\n",
              "  'start_time': 579.293,\n",
              "  'end_time': 589.96},\n",
              " {'chunk_id': 110,\n",
              "  'chunk_length': 8.966,\n",
              "  'text': 'Now those models are I mean as I said you know I think that there is space for all of those things and I think as when Sridhar was talking about',\n",
              "  'start_time': 589.96,\n",
              "  'end_time': 598.926},\n",
              " {'chunk_id': 111,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"earlier in the day, we believe that these smaller models can do many many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas and so therefore the value of these kinds of things, we are not aiming in these more set of models to build any AGI, that's not our goal.\",\n",
              "  'start_time': 598.926,\n",
              "  'end_time': 613.926},\n",
              " {'chunk_id': 112,\n",
              "  'chunk_length': 9.324,\n",
              "  'text': \"earlier in the day, we believe that these smaller models can do many many kind of domain specific tasks extremely well, probably even better than the larger models and that is really one of the key areas and so therefore the value of these kinds of things, we are not aiming in these more set of models to build any AGI, that's not our goal.\",\n",
              "  'start_time': 613.926,\n",
              "  'end_time': 623.25},\n",
              " {'chunk_id': 113,\n",
              "  'chunk_length': 11.71,\n",
              "  'text': 'Our goal is to make things that work extremely well for domain specific use cases or increase accessibility to language and obviously all of this unique to India.',\n",
              "  'start_time': 623.25,\n",
              "  'end_time': 634.96},\n",
              " {'chunk_id': 114,\n",
              "  'chunk_length': 1.481,\n",
              "  'text': 'What is unique about India?',\n",
              "  'start_time': 634.96,\n",
              "  'end_time': 636.441},\n",
              " {'chunk_id': 115,\n",
              "  'chunk_length': 10.569,\n",
              "  'text': 'Is there anything special in our ecosystem that makes small models focused with Indian languages more suited for our problems?',\n",
              "  'start_time': 636.441,\n",
              "  'end_time': 647.01},\n",
              " {'chunk_id': 116,\n",
              "  'chunk_length': 6.248,\n",
              "  'text': 'So I think that, I mean, there are quite a few things that are unique about India, right?',\n",
              "  'start_time': 647.01,\n",
              "  'end_time': 653.258},\n",
              " {'chunk_id': 117,\n",
              "  'chunk_length': 4.545,\n",
              "  'text': 'The first thing is I think that we are a voice first nations.',\n",
              "  'start_time': 653.258,\n",
              "  'end_time': 657.803},\n",
              " {'chunk_id': 118,\n",
              "  'chunk_length': 3.564,\n",
              "  'text': 'Therefore, I think voice has to be the core to doing things.',\n",
              "  'start_time': 657.803,\n",
              "  'end_time': 661.367},\n",
              " {'chunk_id': 119,\n",
              "  'chunk_length': 8.698,\n",
              "  'text': 'The other thing, of course, India is a cost-conscious country from a cost perspective.',\n",
              "  'start_time': 661.367,\n",
              "  'end_time': 670.065},\n",
              " {'chunk_id': 120,\n",
              "  'chunk_length': 8.645,\n",
              "  'text': 'I would say that there are lots of interesting use cases where you can use OpenAI and the cost structure works depending on your application.',\n",
              "  'start_time': 670.065,\n",
              "  'end_time': 678.71},\n",
              " {'chunk_id': 121,\n",
              "  'chunk_length': 6.444,\n",
              "  'text': 'But when you want to scale things to a massive level and make it work, then you have to figure out how small amounts work.',\n",
              "  'start_time': 678.71,\n",
              "  'end_time': 685.154},\n",
              " {'chunk_id': 122,\n",
              "  'chunk_length': 3.122,\n",
              "  'text': \"So that's something that is also specific to India.\",\n",
              "  'start_time': 685.154,\n",
              "  'end_time': 688.276},\n",
              " {'chunk_id': 123,\n",
              "  'chunk_length': 7.505,\n",
              "  'text': 'The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure.',\n",
              "  'start_time': 688.276,\n",
              "  'end_time': 695.781},\n",
              " {'chunk_id': 124,\n",
              "  'chunk_length': 12.087,\n",
              "  'text': 'When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that.',\n",
              "  'start_time': 695.781,\n",
              "  'end_time': 707.868},\n",
              " {'chunk_id': 125,\n",
              "  'chunk_length': 0.981,\n",
              "  'text': \"That's a phenomenal point.\",\n",
              "  'start_time': 707.868,\n",
              "  'end_time': 708.849},\n",
              " {'chunk_id': 126,\n",
              "  'chunk_length': 2.942,\n",
              "  'text': \"Like, you know, it's like DPI to the power of AI almost in some ways.\",\n",
              "  'start_time': 708.849,\n",
              "  'end_time': 711.791},\n",
              " {'chunk_id': 127,\n",
              "  'chunk_length': 3.962,\n",
              "  'text': \"It's a part of Adhar, building Adhar, no better person than you.\",\n",
              "  'start_time': 711.791,\n",
              "  'end_time': 715.753},\n",
              " {'chunk_id': 128,\n",
              "  'chunk_length': 13.124,\n",
              "  'text': 'So, in summary what I am hearing is small models specialized with trained with big specific language data suited for Indian problems at a compelling cost point will be suited for us.',\n",
              "  'start_time': 715.753,\n",
              "  'end_time': 728.877},\n",
              " {'chunk_id': 129,\n",
              "  'chunk_length': 3.864,\n",
              "  'text': 'We are not solving some world or some complex problem.',\n",
              "  'start_time': 728.877,\n",
              "  'end_time': 732.741},\n",
              " {'chunk_id': 130,\n",
              "  'chunk_length': 0.501,\n",
              "  'text': 'We are solving',\n",
              "  'start_time': 732.741,\n",
              "  'end_time': 733.242},\n",
              " {'chunk_id': 131,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"basic problems specifically focus with on voice of multiple languages that is what you see as the future am I paraphrasing this correctly no yeah so I think that certainly I mean a voice at Indian languages are an important part of our strategy but we will be building you know custom models to solve various other kinds of problems as well right it's not just limited to I think in different domains\",\n",
              "  'start_time': 733.242,\n",
              "  'end_time': 748.242},\n",
              " {'chunk_id': 132,\n",
              "  'chunk_length': 8.851,\n",
              "  'text': \"basic problems specifically focus with on voice of multiple languages that is what you see as the future am I paraphrasing this correctly no yeah so I think that certainly I mean a voice at Indian languages are an important part of our strategy but we will be building you know custom models to solve various other kinds of problems as well right it's not just limited to I think in different domains\",\n",
              "  'start_time': 748.242,\n",
              "  'end_time': 757.093},\n",
              " {'chunk_id': 133,\n",
              "  'chunk_length': 5.726,\n",
              "  'text': 'domains making building things based on unique data that enterprises have.',\n",
              "  'start_time': 757.093,\n",
              "  'end_time': 762.819},\n",
              " {'chunk_id': 134,\n",
              "  'chunk_length': 2.182,\n",
              "  'text': \"So that's something.\",\n",
              "  'start_time': 762.819,\n",
              "  'end_time': 765.001},\n",
              " {'chunk_id': 135,\n",
              "  'chunk_length': 0.741,\n",
              "  'text': 'Fair enough.',\n",
              "  'start_time': 765.001,\n",
              "  'end_time': 765.742},\n",
              " {'chunk_id': 136,\n",
              "  'chunk_length': 5.346,\n",
              "  'text': 'So coming back to the elephant in the room, no pun intended with open Hati.',\n",
              "  'start_time': 765.742,\n",
              "  'end_time': 771.088},\n",
              " {'chunk_id': 137,\n",
              "  'chunk_length': 2.743,\n",
              "  'text': 'What about Bhavesh Atirwal and Kruthiram?',\n",
              "  'start_time': 771.088,\n",
              "  'end_time': 773.831},\n",
              " {'chunk_id': 138,\n",
              "  'chunk_length': 1.414,\n",
              "  'text': 'What is your take on it?',\n",
              "  'start_time': 773.831,\n",
              "  'end_time': 775.245},\n",
              " {'chunk_id': 139,\n",
              "  'chunk_length': 1.041,\n",
              "  'text': \"I think it's great.\",\n",
              "  'start_time': 775.245,\n",
              "  'end_time': 776.286},\n",
              " {'chunk_id': 140,\n",
              "  'chunk_length': 1.901,\n",
              "  'text': \"I think it's wonderful, right?\",\n",
              "  'start_time': 776.286,\n",
              "  'end_time': 778.187},\n",
              " {'chunk_id': 141,\n",
              "  'chunk_length': 7.305,\n",
              "  'text': 'I mean the fact that the technology, AI is so important that we need multiple people working on it.',\n",
              "  'start_time': 778.187,\n",
              "  'end_time': 785.492},\n",
              " {'chunk_id': 142,\n",
              "  'chunk_length': 6.024,\n",
              "  'text': 'The fact that there are other people thinking is actually validates that this is an important problem to be solved.',\n",
              "  'start_time': 785.492,\n",
              "  'end_time': 791.516},\n",
              " {'chunk_id': 143,\n",
              "  'chunk_length': 5.82,\n",
              "  'text': 'And I think that we need everybody to come together and do that.',\n",
              "  'start_time': 791.516,\n",
              "  'end_time': 797.336},\n",
              " {'chunk_id': 144,\n",
              "  'chunk_length': 1.642,\n",
              "  'text': 'So I really welcome that.',\n",
              "  'start_time': 797.336,\n",
              "  'end_time': 798.978},\n",
              " {'chunk_id': 145,\n",
              "  'chunk_length': 1.041,\n",
              "  'text': \"I think it's great.\",\n",
              "  'start_time': 798.978,\n",
              "  'end_time': 800.019},\n",
              " {'chunk_id': 146,\n",
              "  'chunk_length': 6.146,\n",
              "  'text': 'And I think that there will be different people will have different takes as to how to solve this kind of problem.',\n",
              "  'start_time': 800.019,\n",
              "  'end_time': 806.165},\n",
              " {'chunk_id': 147,\n",
              "  'chunk_length': 4.244,\n",
              "  'text': 'And hopefully as a result of that, the entire ecosystem benefits.',\n",
              "  'start_time': 806.165,\n",
              "  'end_time': 810.409},\n",
              " {'chunk_id': 148,\n",
              "  'chunk_length': 5.787,\n",
              "  'text': 'I have one more question and then I want to talk about some of the predictions that you boldly made.',\n",
              "  'start_time': 810.409,\n",
              "  'end_time': 816.196},\n",
              " {'chunk_id': 149,\n",
              "  'chunk_length': 4.301,\n",
              "  'text': 'So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges.',\n",
              "  'start_time': 816.196,\n",
              "  'end_time': 820.497},\n",
              " {'chunk_id': 150,\n",
              "  'chunk_length': 3.441,\n",
              "  'text': 'I ask Vivek, what do you think is going to happen by December 2024?',\n",
              "  'start_time': 820.497,\n",
              "  'end_time': 823.938},\n",
              " {'chunk_id': 151,\n",
              "  'chunk_length': 3.961,\n",
              "  'text': 'What do you think sitting in this room one year later we can expect?',\n",
              "  'start_time': 823.938,\n",
              "  'end_time': 827.899},\n",
              " {'chunk_id': 152,\n",
              "  'chunk_length': 1.94,\n",
              "  'text': 'And he made three bold predictions.',\n",
              "  'start_time': 827.899,\n",
              "  'end_time': 829.839},\n",
              " {'chunk_id': 153,\n",
              "  'chunk_length': 1.741,\n",
              "  'text': 'So I want to talk about that.',\n",
              "  'start_time': 829.839,\n",
              "  'end_time': 831.58},\n",
              " {'chunk_id': 154,\n",
              "  'chunk_length': 1.36,\n",
              "  'text': 'Before that I have one last question.',\n",
              "  'start_time': 831.58,\n",
              "  'end_time': 832.94},\n",
              " {'chunk_id': 155,\n",
              "  'chunk_length': 5.044,\n",
              "  'text': 'What are the top three applications that you think are relevant for India?',\n",
              "  'start_time': 832.94,\n",
              "  'end_time': 837.984},\n",
              " {'chunk_id': 156,\n",
              "  'chunk_length': 1.521,\n",
              "  'text': 'You heard Sridhar talk about medical.',\n",
              "  'start_time': 837.984,\n",
              "  'end_time': 839.505},\n",
              " {'chunk_id': 157,\n",
              "  'chunk_length': 4.924,\n",
              "  'text': 'Quick summary, what do you think the top three apps are for India for AI?',\n",
              "  'start_time': 839.505,\n",
              "  'end_time': 844.429},\n",
              " {'chunk_id': 158,\n",
              "  'chunk_length': 10.628,\n",
              "  'text': 'So I mean I think that as I said things like education and medical are clearly areas where I think that can be leveraged.',\n",
              "  'start_time': 844.429,\n",
              "  'end_time': 855.057},\n",
              " {'chunk_id': 159,\n",
              "  'chunk_length': 1.401,\n",
              "  'text': 'The whole idea of',\n",
              "  'start_time': 855.057,\n",
              "  'end_time': 856.458},\n",
              " {'chunk_id': 160,\n",
              "  'chunk_length': 5.863,\n",
              "  'text': 'or these kind of the DPI aspect of it is another major application where things can happen.',\n",
              "  'start_time': 856.458,\n",
              "  'end_time': 862.321},\n",
              " {'chunk_id': 161,\n",
              "  'chunk_length': 2.261,\n",
              "  'text': \"And here I'm talking about country specific work.\",\n",
              "  'start_time': 862.321,\n",
              "  'end_time': 864.582},\n",
              " {'chunk_id': 162,\n",
              "  'chunk_length': 5.403,\n",
              "  'text': 'And I think the whole idea which you also talked about was the concept of software, right?',\n",
              "  'start_time': 864.582,\n",
              "  'end_time': 869.985},\n",
              " {'chunk_id': 163,\n",
              "  'chunk_length': 6.184,\n",
              "  'text': 'And I think that and clearly we have a very large software industry and how to reimagine those things.',\n",
              "  'start_time': 869.985,\n",
              "  'end_time': 876.169},\n",
              " {'chunk_id': 164,\n",
              "  'chunk_length': 1.961,\n",
              "  'text': \"This context is also something that's coming.\",\n",
              "  'start_time': 876.169,\n",
              "  'end_time': 878.13},\n",
              " {'chunk_id': 165,\n",
              "  'chunk_length': 1.881,\n",
              "  'text': 'Fair enough.',\n",
              "  'start_time': 878.13,\n",
              "  'end_time': 880.011},\n",
              " {'chunk_id': 166,\n",
              "  'chunk_length': 3.642,\n",
              "  'text': \"Are you guys ready for Vivek Radwan's bold predictions?\",\n",
              "  'start_time': 880.011,\n",
              "  'end_time': 883.653},\n",
              " {'chunk_id': 167,\n",
              "  'chunk_length': 1.241,\n",
              "  'text': 'Yeah?',\n",
              "  'start_time': 883.653,\n",
              "  'end_time': 884.894},\n",
              " {'chunk_id': 168,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"no I'm not hearing any yes this is like a big deal he's like one of the smartest guys that I know he wants to make three predictions you don't want to hear it all right so I asked him what do you think you know here later what what do you think we can expect and he came up with three things and usually people give very blah answers when they ask questions like this because they don't want to be caught wrong not be vague, vague is bold so he basically said three things and I want to list out the three things and then\",\n",
              "  'start_time': 884.894,\n",
              "  'end_time': 899.894},\n",
              " {'chunk_id': 169,\n",
              "  'chunk_length': 11.832,\n",
              "  'text': \"no I'm not hearing any yes this is like a big deal he's like one of the smartest guys that I know he wants to make three predictions you don't want to hear it all right so I asked him what do you think you know here later what what do you think we can expect and he came up with three things and usually people give very blah answers when they ask questions like this because they don't want to be caught wrong not be vague, vague is bold so he basically said three things and I want to list out the three things and then\",\n",
              "  'start_time': 899.894,\n",
              "  'end_time': 911.726},\n",
              " {'chunk_id': 170,\n",
              "  'chunk_length': 1.374,\n",
              "  'text': 'ask him about it.',\n",
              "  'start_time': 911.726,\n",
              "  'end_time': 913.1},\n",
              " {'chunk_id': 171,\n",
              "  'chunk_length': 8.226,\n",
              "  'text': 'So number one he says I would prefer to talk to an automated customer service than a real person because they give me a better answer.',\n",
              "  'start_time': 913.1,\n",
              "  'end_time': 921.326},\n",
              " {'chunk_id': 172,\n",
              "  'chunk_length': 2.262,\n",
              "  'text': \"That is Vivek Ragwan's prediction number one.\",\n",
              "  'start_time': 921.326,\n",
              "  'end_time': 923.588},\n",
              " {'chunk_id': 173,\n",
              "  'chunk_length': 9.067,\n",
              "  'text': 'So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there will be a GPU glut in India.',\n",
              "  'start_time': 923.588,\n",
              "  'end_time': 932.655},\n",
              " {'chunk_id': 174,\n",
              "  'chunk_length': 1.121,\n",
              "  'text': 'He thinks there will be too much GPU.',\n",
              "  'start_time': 932.655,\n",
              "  'end_time': 933.776},\n",
              " {'chunk_id': 175,\n",
              "  'chunk_length': 4.02,\n",
              "  'text': \"So, if you want a short in-media stock, it's a good time.\",\n",
              "  'start_time': 933.776,\n",
              "  'end_time': 937.796},\n",
              " {'chunk_id': 176,\n",
              "  'chunk_length': 6.366,\n",
              "  'text': 'And number 3, which was extremely unexpected, he said some companies will suddenly die.',\n",
              "  'start_time': 937.796,\n",
              "  'end_time': 944.162},\n",
              " {'chunk_id': 177,\n",
              "  'chunk_length': 3.619,\n",
              "  'text': 'not what I expected.',\n",
              "  'start_time': 944.162,\n",
              "  'end_time': 947.781},\n",
              " {'chunk_id': 178,\n",
              "  'chunk_length': 9.027,\n",
              "  'text': \"So do you want to quickly talk about each of them, why you just came up with these and then we'll throw the audience questions.\",\n",
              "  'start_time': 947.781,\n",
              "  'end_time': 956.808},\n",
              " {'chunk_id': 179,\n",
              "  'chunk_length': 6.946,\n",
              "  'text': \"So I don't think I quite said it the way that Walai was kind of pointing, but it's interesting.\",\n",
              "  'start_time': 956.808,\n",
              "  'end_time': 963.754},\n",
              " {'chunk_id': 180,\n",
              "  'chunk_length': 8.467,\n",
              "  'text': \"But I think the first thing that we said is I think that, and I don't think that this, I think there will come a time\",\n",
              "  'start_time': 963.754,\n",
              "  'end_time': 972.221},\n",
              " {'chunk_id': 181,\n",
              "  'chunk_length': 5.425,\n",
              "  'text': 'when you know in areas of customer service etc.',\n",
              "  'start_time': 972.221,\n",
              "  'end_time': 977.646},\n",
              " {'chunk_id': 182,\n",
              "  'chunk_length': 2.706,\n",
              "  'text': 'when you want to do something very specific.',\n",
              "  'start_time': 977.646,\n",
              "  'end_time': 980.352},\n",
              " {'chunk_id': 183,\n",
              "  'chunk_length': 10.528,\n",
              "  'text': \"Today, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or you're extremely upset that you're talking to a bot.\",\n",
              "  'start_time': 980.352,\n",
              "  'end_time': 990.88},\n",
              " {'chunk_id': 184,\n",
              "  'chunk_length': 13.766,\n",
              "  'text': \"But I think that there will come a time, and I'm predicting this sooner than later, that you will actually get better responses from the bot than what the human representative, at least the average human representative that people talk to,\",\n",
              "  'start_time': 990.88,\n",
              "  'end_time': 1004.646},\n",
              " {'chunk_id': 185,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"could give and I think that that's just I just said that there will come a time where you know it's not a human you're talking to but it's probably more likely to solve your intent that's just something that that that I think that could happen okay definitely controversial but we let it go what about the GPU glut\",\n",
              "  'start_time': 1004.646,\n",
              "  'end_time': 1019.646},\n",
              " {'chunk_id': 186,\n",
              "  'chunk_length': 7.85,\n",
              "  'text': \"could give and I think that that's just I just said that there will come a time where you know it's not a human you're talking to but it's probably more likely to solve your intent that's just something that that that I think that could happen okay definitely controversial but we let it go what about the GPU glut\",\n",
              "  'start_time': 1019.646,\n",
              "  'end_time': 1027.496},\n",
              " {'chunk_id': 187,\n",
              "  'chunk_length': 13.153,\n",
              "  'text': 'I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go.',\n",
              "  'start_time': 1027.496,\n",
              "  'end_time': 1040.649},\n",
              " {'chunk_id': 188,\n",
              "  'chunk_length': 13.708,\n",
              "  'text': 'I think the fact that there was such a severe shortage last year basically caused a number of different players to ramp up in various kinds of forms and I think that will always go in cycles.',\n",
              "  'start_time': 1040.649,\n",
              "  'end_time': 1054.357},\n",
              " {'chunk_id': 189,\n",
              "  'chunk_length': 5.544,\n",
              "  'text': 'But we may find out that there are many more interesting problems that people will be able to solve.',\n",
              "  'start_time': 1054.357,\n",
              "  'end_time': 1059.901},\n",
              " {'chunk_id': 190,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': 'I still remember, you know, we were at a JNEI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundred?',\n",
              "  'start_time': 1059.901,\n",
              "  'end_time': 1074.901},\n",
              " {'chunk_id': 191,\n",
              "  'chunk_length': 0.392,\n",
              "  'text': 'I still remember, you know, we were at a JNEI event in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, four A-hundred?',\n",
              "  'start_time': 1074.901,\n",
              "  'end_time': 1075.293},\n",
              " {'chunk_id': 192,\n",
              "  'chunk_length': 1.261,\n",
              "  'text': 'This was the question that I had asked.',\n",
              "  'start_time': 1075.293,\n",
              "  'end_time': 1076.554},\n",
              " {'chunk_id': 193,\n",
              "  'chunk_length': 1.281,\n",
              "  'text': 'And nobody in the room.',\n",
              "  'start_time': 1076.554,\n",
              "  'end_time': 1077.835},\n",
              " {'chunk_id': 194,\n",
              "  'chunk_length': 2.102,\n",
              "  'text': 'And these are all extremely enthusiastic JNEI people.',\n",
              "  'start_time': 1077.835,\n",
              "  'end_time': 1079.937},\n",
              " {'chunk_id': 195,\n",
              "  'chunk_length': 1.515,\n",
              "  'text': 'And nobody had access.',\n",
              "  'start_time': 1079.937,\n",
              "  'end_time': 1081.452},\n",
              " {'chunk_id': 196,\n",
              "  'chunk_length': 1.961,\n",
              "  'text': 'And I think that thing is going to change.',\n",
              "  'start_time': 1081.452,\n",
              "  'end_time': 1083.413},\n",
              " {'chunk_id': 197,\n",
              "  'chunk_length': 2.021,\n",
              "  'text': 'You will be able to get these kinds of things.',\n",
              "  'start_time': 1083.413,\n",
              "  'end_time': 1085.434},\n",
              " {'chunk_id': 198,\n",
              "  'chunk_length': 9.124,\n",
              "  'text': 'And people who want to hack and do things will have access to these things without having to write a check.',\n",
              "  'start_time': 1085.434,\n",
              "  'end_time': 1094.558},\n",
              " {'chunk_id': 199,\n",
              "  'chunk_length': 2.181,\n",
              "  'text': 'Vivek is also a semiconductor guy.',\n",
              "  'start_time': 1094.558,\n",
              "  'end_time': 1096.739},\n",
              " {'chunk_id': 200,\n",
              "  'chunk_length': 1.061,\n",
              "  'text': 'Before he went into Adar.',\n",
              "  'start_time': 1096.739,\n",
              "  'end_time': 1097.8},\n",
              " {'chunk_id': 201,\n",
              "  'chunk_length': 2.521,\n",
              "  'text': 'So I would take his predictions very seriously.',\n",
              "  'start_time': 1097.8,\n",
              "  'end_time': 1100.321},\n",
              " {'chunk_id': 202,\n",
              "  'chunk_length': 1.1,\n",
              "  'text': \"So I don't know what I would do.\",\n",
              "  'start_time': 1100.321,\n",
              "  'end_time': 1101.421},\n",
              " {'chunk_id': 203,\n",
              "  'chunk_length': 1.221,\n",
              "  'text': 'I would sell my previous stock.',\n",
              "  'start_time': 1101.421,\n",
              "  'end_time': 1102.642},\n",
              " {'chunk_id': 204,\n",
              "  'chunk_length': 1.901,\n",
              "  'text': 'I would not do that.',\n",
              "  'start_time': 1102.642,\n",
              "  'end_time': 1104.543},\n",
              " {'chunk_id': 205,\n",
              "  'chunk_length': 1.42,\n",
              "  'text': \"But that's not what I said.\",\n",
              "  'start_time': 1104.543,\n",
              "  'end_time': 1105.963},\n",
              " {'chunk_id': 206,\n",
              "  'chunk_length': 3.102,\n",
              "  'text': \"I don't want to blame you for this.\",\n",
              "  'start_time': 1105.963,\n",
              "  'end_time': 1109.065},\n",
              " {'chunk_id': 207,\n",
              "  'chunk_length': 3.385,\n",
              "  'text': 'But the third one is pretty strange.',\n",
              "  'start_time': 1109.065,\n",
              "  'end_time': 1112.45},\n",
              " {'chunk_id': 208,\n",
              "  'chunk_length': 2.507,\n",
              "  'text': 'Companies are born, companies die.',\n",
              "  'start_time': 1112.45,\n",
              "  'end_time': 1114.957},\n",
              " {'chunk_id': 209,\n",
              "  'chunk_length': 2.686,\n",
              "  'text': 'But you said some companies will suddenly die.',\n",
              "  'start_time': 1114.957,\n",
              "  'end_time': 1117.643},\n",
              " {'chunk_id': 210,\n",
              "  'chunk_length': 1.04,\n",
              "  'text': 'What does that mean?',\n",
              "  'start_time': 1117.643,\n",
              "  'end_time': 1118.683},\n",
              " {'chunk_id': 211,\n",
              "  'chunk_length': 8.005,\n",
              "  'text': 'No, I think, see, I think the interesting thing is, and I think that it comes back to the fundamental nature of AI.',\n",
              "  'start_time': 1118.683,\n",
              "  'end_time': 1126.688},\n",
              " {'chunk_id': 212,\n",
              "  'chunk_length': 2.362,\n",
              "  'text': 'AI is a tool, right?',\n",
              "  'start_time': 1126.688,\n",
              "  'end_time': 1129.05},\n",
              " {'chunk_id': 213,\n",
              "  'chunk_length': 1.341,\n",
              "  'text': 'And you have to use that.',\n",
              "  'start_time': 1129.05,\n",
              "  'end_time': 1130.391},\n",
              " {'chunk_id': 214,\n",
              "  'chunk_length': 4.102,\n",
              "  'text': 'And you have to use that within your business process, right?',\n",
              "  'start_time': 1130.391,\n",
              "  'end_time': 1134.493},\n",
              " {'chunk_id': 215,\n",
              "  'chunk_length': 1.941,\n",
              "  'text': 'And how AI is being used.',\n",
              "  'start_time': 1134.493,\n",
              "  'end_time': 1136.434},\n",
              " {'chunk_id': 216,\n",
              "  'chunk_length': 10.687,\n",
              "  'text': \"And so, and what's going to happen is that, I mean, I think this is true with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI\",\n",
              "  'start_time': 1136.434,\n",
              "  'end_time': 1147.121},\n",
              " {'chunk_id': 217,\n",
              "  'chunk_length': 4.204,\n",
              "  'text': \"will be more effective than those who don't leverage AI.\",\n",
              "  'start_time': 1147.121,\n",
              "  'end_time': 1151.325},\n",
              " {'chunk_id': 218,\n",
              "  'chunk_length': 2.782,\n",
              "  'text': 'And that will speak for organizations also.',\n",
              "  'start_time': 1151.325,\n",
              "  'end_time': 1154.107},\n",
              " {'chunk_id': 219,\n",
              "  'chunk_length': 8.686,\n",
              "  'text': \"Organizations that leverage AI fundamentally in their core business processes will be more effective than those who don't.\",\n",
              "  'start_time': 1154.107,\n",
              "  'end_time': 1162.793},\n",
              " {'chunk_id': 220,\n",
              "  'chunk_length': 1.141,\n",
              "  'text': \"And I think that's the thing.\",\n",
              "  'start_time': 1162.793,\n",
              "  'end_time': 1163.934},\n",
              " {'chunk_id': 221,\n",
              "  'chunk_length': 6.244,\n",
              "  'text': \"And you won't know the difference until one day it becomes too obvious and it will be too late.\",\n",
              "  'start_time': 1163.934,\n",
              "  'end_time': 1170.178},\n",
              " {'chunk_id': 222,\n",
              "  'chunk_length': 6.405,\n",
              "  'text': \"And I think that's the reason why everybody needs to think about what it means for your business.\",\n",
              "  'start_time': 1170.178,\n",
              "  'end_time': 1176.583},\n",
              " {'chunk_id': 223,\n",
              "  'chunk_length': 2.581,\n",
              "  'text': 'Because everything will be fine.',\n",
              "  'start_time': 1176.583,\n",
              "  'end_time': 1179.164},\n",
              " {'chunk_id': 224,\n",
              "  'chunk_length': 11.684,\n",
              "  'text': 'Everything will be fine and one day somebody in your either competitor in your space or something brand new coming into your space will be reimagining your business process completely.',\n",
              "  'start_time': 1179.164,\n",
              "  'end_time': 1190.848},\n",
              " {'chunk_id': 225,\n",
              "  'chunk_length': 5.562,\n",
              "  'text': \"And at that stage you will find that it's a very big, very tall business.\",\n",
              "  'start_time': 1190.848,\n",
              "  'end_time': 1196.41},\n",
              " {'chunk_id': 226,\n",
              "  'chunk_length': 13.186,\n",
              "  'text': \"you know mountain to climb and that's why I think it's important for both people and entities to think about how they will you know they will upgrade themselves or they will modify their first system.\",\n",
              "  'start_time': 1196.41,\n",
              "  'end_time': 1209.596},\n",
              " {'chunk_id': 227,\n",
              "  'chunk_length': 7.044,\n",
              "  'text': \"That's a very nuanced answer everybody here running a business should really think about it because life will be the same\",\n",
              "  'start_time': 1209.596,\n",
              "  'end_time': 1216.64},\n",
              " {'chunk_id': 228,\n",
              "  'chunk_length': 3.976,\n",
              "  'text': 'And then suddenly, suddenly something will be a step change.',\n",
              "  'start_time': 1216.64,\n",
              "  'end_time': 1220.616},\n",
              " {'chunk_id': 229,\n",
              "  'chunk_length': 4.562,\n",
              "  'text': \"Vivek, I have a few more questions, but I'm sure the audience has a lot of questions for you.\",\n",
              "  'start_time': 1220.616,\n",
              "  'end_time': 1225.178},\n",
              " {'chunk_id': 230,\n",
              "  'chunk_length': 1.801,\n",
              "  'text': 'So how are we doing on time?',\n",
              "  'start_time': 1225.178,\n",
              "  'end_time': 1226.979},\n",
              " {'chunk_id': 231,\n",
              "  'chunk_length': 1.601,\n",
              "  'text': 'OK.',\n",
              "  'start_time': 1226.979,\n",
              "  'end_time': 1228.58},\n",
              " {'chunk_id': 232,\n",
              "  'chunk_length': 2.441,\n",
              "  'text': \"So that's OK.\",\n",
              "  'start_time': 1228.58,\n",
              "  'end_time': 1231.021},\n",
              " {'chunk_id': 233,\n",
              "  'chunk_length': 1.64,\n",
              "  'text': \"A lot of questions, so I'd love to.\",\n",
              "  'start_time': 1231.021,\n",
              "  'end_time': 1232.661},\n",
              " {'chunk_id': 234,\n",
              "  'chunk_length': 1.661,\n",
              "  'text': 'Is there a mic that we can?',\n",
              "  'start_time': 1232.661,\n",
              "  'end_time': 1234.322},\n",
              " {'chunk_id': 235,\n",
              "  'chunk_length': 6.563,\n",
              "  'text': 'Thank you.',\n",
              "  'start_time': 1234.322,\n",
              "  'end_time': 1240.885},\n",
              " {'chunk_id': 236,\n",
              "  'chunk_length': 1.14,\n",
              "  'text': 'My name is Karthik.',\n",
              "  'start_time': 1240.885,\n",
              "  'end_time': 1242.025},\n",
              " {'chunk_id': 237,\n",
              "  'chunk_length': 3.882,\n",
              "  'text': 'I work for IT service industry.',\n",
              "  'start_time': 1242.025,\n",
              "  'end_time': 1245.907},\n",
              " {'chunk_id': 238,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"so you're saying that you're working on LLM sorry fine-tuned LLM on top of lama my basic question fundamental question is we don't have a foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about\",\n",
              "  'start_time': 1245.907,\n",
              "  'end_time': 1260.907},\n",
              " {'chunk_id': 239,\n",
              "  'chunk_length': 6.37,\n",
              "  'text': \"so you're saying that you're working on LLM sorry fine-tuned LLM on top of lama my basic question fundamental question is we don't have a foundational model for India most of the models are basically using English or those kind of things for example even Andrew was talking about\",\n",
              "  'start_time': 1260.907,\n",
              "  'end_time': 1267.277},\n",
              " {'chunk_id': 240,\n",
              "  'chunk_length': 2.84,\n",
              "  'text': 'tokenizers and things like that.',\n",
              "  'start_time': 1267.277,\n",
              "  'end_time': 1270.117},\n",
              " {'chunk_id': 241,\n",
              "  'chunk_length': 7.482,\n",
              "  'text': 'So are you working on anything like that or you want to use mostly the existing models and run on top of it?',\n",
              "  'start_time': 1270.117,\n",
              "  'end_time': 1277.599},\n",
              " {'chunk_id': 242,\n",
              "  'chunk_length': 1.101,\n",
              "  'text': 'Good question.',\n",
              "  'start_time': 1277.599,\n",
              "  'end_time': 1278.7},\n",
              " {'chunk_id': 243,\n",
              "  'chunk_length': 1.9,\n",
              "  'text': 'You asked a cherry question for us.',\n",
              "  'start_time': 1278.7,\n",
              "  'end_time': 1280.6},\n",
              " {'chunk_id': 244,\n",
              "  'chunk_length': 9.544,\n",
              "  'text': 'No, I think the interesting thing is that if you look at, and we have actually a blog on this, on our website, I think one of the things that we actually built',\n",
              "  'start_time': 1280.6,\n",
              "  'end_time': 1290.144},\n",
              " {'chunk_id': 245,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"a customized tokenizer which actually fundamentally changes the cost of some of these generations in India languages and I think that we are not just we are actually we are leveraging the existing training but we are doing what's known as continual pre-training which actually but having said that you know I think that once we have to figure out where is the data to train an extremely large model from scratch and some of those things are things which will happen\",\n",
              "  'start_time': 1290.144,\n",
              "  'end_time': 1305.144},\n",
              " {'chunk_id': 246,\n",
              "  'chunk_length': 13.737,\n",
              "  'text': \"a customized tokenizer which actually fundamentally changes the cost of some of these generations in India languages and I think that we are not just we are actually we are leveraging the existing training but we are doing what's known as continual pre-training which actually but having said that you know I think that once we have to figure out where is the data to train an extremely large model from scratch and some of those things are things which will happen\",\n",
              "  'start_time': 1305.144,\n",
              "  'end_time': 1318.881},\n",
              " {'chunk_id': 247,\n",
              "  'chunk_length': 1.52,\n",
              "  'text': 'over time.',\n",
              "  'start_time': 1318.881,\n",
              "  'end_time': 1320.401},\n",
              " {'chunk_id': 248,\n",
              "  'chunk_length': 6.223,\n",
              "  'text': 'But I think that yes, I think that we will be doing various kinds of things.',\n",
              "  'start_time': 1320.401,\n",
              "  'end_time': 1326.624},\n",
              " {'chunk_id': 249,\n",
              "  'chunk_length': 7.723,\n",
              "  'text': 'But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that?',\n",
              "  'start_time': 1326.624,\n",
              "  'end_time': 1334.347},\n",
              " {'chunk_id': 250,\n",
              "  'chunk_length': 3.381,\n",
              "  'text': \"And that's the problem that we think we have solved.\",\n",
              "  'start_time': 1334.347,\n",
              "  'end_time': 1337.728},\n",
              " {'chunk_id': 251,\n",
              "  'chunk_length': 2.701,\n",
              "  'text': \"And it's going to be the heart of this.\",\n",
              "  'start_time': 1337.728,\n",
              "  'end_time': 1340.429},\n",
              " {'chunk_id': 252,\n",
              "  'chunk_length': 2.681,\n",
              "  'text': \"It's extremely well explained in the blog, even I could understand.\",\n",
              "  'start_time': 1340.429,\n",
              "  'end_time': 1343.11},\n",
              " {'chunk_id': 253,\n",
              "  'chunk_length': 3.321,\n",
              "  'text': \"Hi, I'm Prashanth.\",\n",
              "  'start_time': 1343.11,\n",
              "  'end_time': 1346.431},\n",
              " {'chunk_id': 254,\n",
              "  'chunk_length': 1.361,\n",
              "  'text': 'I work for a fintech company.',\n",
              "  'start_time': 1346.431,\n",
              "  'end_time': 1347.792},\n",
              " {'chunk_id': 255,\n",
              "  'chunk_length': 10.862,\n",
              "  'text': 'My question is like, unlike China, we never had a consumer facing application coming out from India and in web one, web two, crypto and on.',\n",
              "  'start_time': 1347.792,\n",
              "  'end_time': 1358.654},\n",
              " {'chunk_id': 256,\n",
              "  'chunk_length': 5.481,\n",
              "  'text': 'Why do you think it would be different this time in like AI?',\n",
              "  'start_time': 1358.654,\n",
              "  'end_time': 1364.135},\n",
              " {'chunk_id': 257,\n",
              "  'chunk_length': 8.703,\n",
              "  'text': 'Because will the DPI and other things will serve the same purpose what the Great Firewall did in China?',\n",
              "  'start_time': 1364.135,\n",
              "  'end_time': 1372.838},\n",
              " {'chunk_id': 258,\n",
              "  'chunk_length': 4.521,\n",
              "  'text': 'Or do you think like, because AI is a strategic sector,',\n",
              "  'start_time': 1372.838,\n",
              "  'end_time': 1377.359},\n",
              " {'chunk_id': 259,\n",
              "  'chunk_length': 7.817,\n",
              "  'text': 'no outside country can work in NASA projects, maybe all government content will go to them.',\n",
              "  'start_time': 1377.359,\n",
              "  'end_time': 1385.176},\n",
              " {'chunk_id': 260,\n",
              "  'chunk_length': 3.364,\n",
              "  'text': 'What is at least the mode here for any income?',\n",
              "  'start_time': 1385.176,\n",
              "  'end_time': 1388.54},\n",
              " {'chunk_id': 261,\n",
              "  'chunk_length': 6.909,\n",
              "  'text': 'So, I think the question is,',\n",
              "  'start_time': 1388.54,\n",
              "  'end_time': 1395.449},\n",
              " {'chunk_id': 262,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"I don't know the answer to these questions right I mean I think that it's difficult to predict but I do believe and as I am repeating that the combinatorial effect of reusing Gen AI at a large scale in addition in along with the DPI work that we have done in India\",\n",
              "  'start_time': 1395.449,\n",
              "  'end_time': 1410.449},\n",
              " {'chunk_id': 263,\n",
              "  'chunk_length': 3.028,\n",
              "  'text': \"I don't know the answer to these questions right I mean I think that it's difficult to predict but I do believe and as I am repeating that the combinatorial effect of reusing Gen AI at a large scale in addition in along with the DPI work that we have done in India\",\n",
              "  'start_time': 1410.449,\n",
              "  'end_time': 1413.477},\n",
              " {'chunk_id': 264,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': \"will have people and I and I think that in the end it is the intent is that people need to be able to use it and they will vote by things that are useful for them and if that doesn't happen you're right that that I think that we have to figure out what is the mechanism of delivery of apps right I mean how where do Indians consume\",\n",
              "  'start_time': 1413.477,\n",
              "  'end_time': 1428.477},\n",
              " {'chunk_id': 265,\n",
              "  'chunk_length': 6.867,\n",
              "  'text': \"will have people and I and I think that in the end it is the intent is that people need to be able to use it and they will vote by things that are useful for them and if that doesn't happen you're right that that I think that we have to figure out what is the mechanism of delivery of apps right I mean how where do Indians consume\",\n",
              "  'start_time': 1428.477,\n",
              "  'end_time': 1435.344},\n",
              " {'chunk_id': 266,\n",
              "  'chunk_length': 3.826,\n",
              "  'text': 'I am so sorry, but we are out of time.',\n",
              "  'start_time': 1435.344,\n",
              "  'end_time': 1439.17},\n",
              " {'chunk_id': 267,\n",
              "  'chunk_length': 1.38,\n",
              "  'text': 'Vivek will be outside.',\n",
              "  'start_time': 1439.17,\n",
              "  'end_time': 1440.55},\n",
              " {'chunk_id': 268,\n",
              "  'chunk_length': 2.701,\n",
              "  'text': 'So he will be able to answer the question.',\n",
              "  'start_time': 1440.55,\n",
              "  'end_time': 1443.251},\n",
              " {'chunk_id': 269,\n",
              "  'chunk_length': 1.161,\n",
              "  'text': 'We have time for one last question.',\n",
              "  'start_time': 1443.251,\n",
              "  'end_time': 1444.412},\n",
              " {'chunk_id': 270,\n",
              "  'chunk_length': 1.76,\n",
              "  'text': 'Can I just take one last?',\n",
              "  'start_time': 1444.412,\n",
              "  'end_time': 1446.172},\n",
              " {'chunk_id': 271,\n",
              "  'chunk_length': 0.24,\n",
              "  'text': 'Yeah.',\n",
              "  'start_time': 1446.172,\n",
              "  'end_time': 1446.412},\n",
              " {'chunk_id': 272,\n",
              "  'chunk_length': 1.081,\n",
              "  'text': 'Thank you.',\n",
              "  'start_time': 1446.412,\n",
              "  'end_time': 1447.493},\n",
              " {'chunk_id': 273,\n",
              "  'chunk_length': 0.44,\n",
              "  'text': 'Thank you.',\n",
              "  'start_time': 1447.493,\n",
              "  'end_time': 1447.933},\n",
              " {'chunk_id': 274,\n",
              "  'chunk_length': 1.04,\n",
              "  'text': 'I am Manish Kothari.',\n",
              "  'start_time': 1447.933,\n",
              "  'end_time': 1448.973},\n",
              " {'chunk_id': 275,\n",
              "  'chunk_length': 1.681,\n",
              "  'text': 'I am from ISBR Business School.',\n",
              "  'start_time': 1448.973,\n",
              "  'end_time': 1450.654},\n",
              " {'chunk_id': 276,\n",
              "  'chunk_length': 2.221,\n",
              "  'text': 'Good that I got a chance to ask you this question.',\n",
              "  'start_time': 1450.654,\n",
              "  'end_time': 1452.875},\n",
              " {'chunk_id': 277,\n",
              "  'chunk_length': 4.902,\n",
              "  'text': 'During lunchtime, there were a few of our educationists whom we were talking about.',\n",
              "  'start_time': 1452.875,\n",
              "  'end_time': 1457.777},\n",
              " {'chunk_id': 278,\n",
              "  'chunk_length': 3.661,\n",
              "  'text': 'There was one from school and we are from the MBA institutions.',\n",
              "  'start_time': 1457.777,\n",
              "  'end_time': 1461.438},\n",
              " {'chunk_id': 279,\n",
              "  'chunk_length': 2.461,\n",
              "  'text': 'We were thinking of these present generations.',\n",
              "  'start_time': 1461.438,\n",
              "  'end_time': 1463.899},\n",
              " {'chunk_id': 280,\n",
              "  'chunk_length': 2.721,\n",
              "  'text': 'How do we get them into what you are doing?',\n",
              "  'start_time': 1463.899,\n",
              "  'end_time': 1466.62},\n",
              " {'chunk_id': 281,\n",
              "  'chunk_length': 13.211,\n",
              "  'text': 'There is one thing that they have been regularly that the concentrations that they are working on but artificial intelligence and getting into this, getting them into their academics and making them a part of it is very important including the trainers who train them.',\n",
              "  'start_time': 1466.62,\n",
              "  'end_time': 1479.831},\n",
              " {'chunk_id': 282,\n",
              "  'chunk_length': 6.353,\n",
              "  'text': 'Making them future ready into what you are doing is amazing and the speed that with which is growing.',\n",
              "  'start_time': 1479.831,\n",
              "  'end_time': 1486.184},\n",
              " {'chunk_id': 283,\n",
              "  'chunk_length': 3.462,\n",
              "  'text': 'It is calling for a lot of training that needs to be done.',\n",
              "  'start_time': 1486.184,\n",
              "  'end_time': 1489.646},\n",
              " {'chunk_id': 284,\n",
              "  'chunk_length': 4.864,\n",
              "  'text': 'Can you from your angle through some light on how we could make them future ready?',\n",
              "  'start_time': 1489.646,\n",
              "  'end_time': 1494.51},\n",
              " {'chunk_id': 285,\n",
              "  'chunk_length': 5.724,\n",
              "  'text': 'How these people who are who are management graduates and from schools who are coming out?',\n",
              "  'start_time': 1494.51,\n",
              "  'end_time': 1500.234},\n",
              " {'chunk_id': 286,\n",
              "  'chunk_length': 3.263,\n",
              "  'text': 'How do we get into this part of technology that you spoke about?',\n",
              "  'start_time': 1500.234,\n",
              "  'end_time': 1503.497},\n",
              " {'chunk_id': 287,\n",
              "  'chunk_length': 15.0,\n",
              "  'text': 'This is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right?',\n",
              "  'start_time': 1503.497,\n",
              "  'end_time': 1518.497},\n",
              " {'chunk_id': 288,\n",
              "  'chunk_length': 3.607,\n",
              "  'text': 'This is really a challenge because I think everyone will need to understand at some level what this technology does and I think that we have to rethink how we get everyone into this and that this kind of education has to be at many different levels, right?',\n",
              "  'start_time': 1518.497,\n",
              "  'end_time': 1522.104},\n",
              " {'chunk_id': 289,\n",
              "  'chunk_length': 4.382,\n",
              "  'text': 'There are from a core set of having people who are extremely good',\n",
              "  'start_time': 1522.104,\n",
              "  'end_time': 1526.486},\n",
              " {'chunk_id': 290,\n",
              "  'chunk_length': 7.545,\n",
              "  'text': \"And there you don't need as many, but then there are vast numbers of people who can actually leverage these tools.\",\n",
              "  'start_time': 1526.486,\n",
              "  'end_time': 1534.031},\n",
              " {'chunk_id': 291,\n",
              "  'chunk_length': 10.206,\n",
              "  'text': \"By the way, the most important thing about, and maybe that's part of what makes an LLM interesting, is that how you use it, your mileage varies by that.\",\n",
              "  'start_time': 1534.031,\n",
              "  'end_time': 1544.237},\n",
              " {'chunk_id': 292,\n",
              "  'chunk_length': 8.003,\n",
              "  'text': 'And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people.',\n",
              "  'start_time': 1544.237,\n",
              "  'end_time': 1552.24},\n",
              " {'chunk_id': 293,\n",
              "  'chunk_length': 11.004,\n",
              "  'text': 'And because asking the things in the right way and having the right kind of applications will make a difference in how people get used to this.',\n",
              "  'start_time': 1552.24,\n",
              "  'end_time': 1563.244},\n",
              " {'chunk_id': 294,\n",
              "  'chunk_length': 0.16,\n",
              "  'text': 'Awesome.',\n",
              "  'start_time': 1563.244,\n",
              "  'end_time': 1563.404},\n",
              " {'chunk_id': 295,\n",
              "  'chunk_length': 0.46,\n",
              "  'text': 'Thank you.',\n",
              "  'start_time': 1563.404,\n",
              "  'end_time': 1563.864},\n",
              " {'chunk_id': 296,\n",
              "  'chunk_length': 1.741,\n",
              "  'text': 'Thank you very much Vivek.',\n",
              "  'start_time': 1563.864,\n",
              "  'end_time': 1565.605},\n",
              " {'chunk_id': 297,\n",
              "  'chunk_length': 2.041,\n",
              "  'text': 'Very good luck to Sarvam and good luck to India.',\n",
              "  'start_time': 1565.605,\n",
              "  'end_time': 1567.646},\n",
              " {'chunk_id': 298,\n",
              "  'chunk_length': 2.32,\n",
              "  'text': \"I think it's going to be a lot right on your shoulders.\",\n",
              "  'start_time': 1567.646,\n",
              "  'end_time': 1569.966},\n",
              " {'chunk_id': 299,\n",
              "  'chunk_length': 1.381,\n",
              "  'text': 'Thanks, Vala.',\n",
              "  'start_time': 1569.966,\n",
              "  'end_time': 1571.347},\n",
              " {'chunk_id': 300,\n",
              "  'chunk_length': 3.408,\n",
              "  'text': 'Thank you Mr. Raghavan.',\n",
              "  'start_time': 1571.347,\n",
              "  'end_time': 1574.755}]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZBzFbIh6kK5y"
      }
    }
  ]
}